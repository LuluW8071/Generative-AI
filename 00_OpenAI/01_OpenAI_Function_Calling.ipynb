{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00. Getting Started\n",
    "\n",
    "- __Activate virtual env (optional):__ To activate the virtual environment enter this your terminal:\n",
    "\n",
    "```bash\n",
    "      source openai-env/bin/activate\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01. OpenAI Function Calling\n",
    "\n",
    "![Open AI](https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2024/01/openai-logo-abstract-background.jpg?ssl=1)\n",
    "\n",
    "#### [Reference Docs](https://platform.openai.com/docs/guides/function-calling)\n",
    "\n",
    "OpenAI **Function Calling** is a feature that allows developers to define **specific functions** that a language model can call during its interactions. This capability extends the model's functionality beyond **text generation** by enabling it to perform predefined **actions** or retrieve **information** from external sources. \n",
    "\n",
    "Developers set up these functions by specifying their **names**, **parameters**, and **descriptions**. During interactions, the model can use these functions to:\n",
    "\n",
    "- **Query databases**\n",
    "- **Execute business logic**\n",
    "- **Retrieve real-time information**\n",
    "\n",
    "This integration enhances the model's ability to handle complex scenarios and deliver more **tailored responses**, making it particularly useful for applications that require dynamic data retrieval or action execution within the conversation flow. Essentially, it enables language models to connect with external tools, thereby broadening their utility and effectiveness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os \n",
    "import openai \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables form .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access environment variables and setup OpenAI client\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.api_key = openai_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero Shot Prompts\n",
    "\n",
    "A **zero-shot prompt** is a type of prompt where you ask a language model to perform a task or answer a question without providing any specific examples or prior training for that particular task. The model is expected to generate a response based on its general understanding and pre-existing knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Lionel Messi, widely regarded as one of the greatest footballers of all time, has amassed a record seven Ballon d'Or awards throughout his illustrious career and, at 37 years old, continues to be a prominent figure in the world of soccer.\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "football_player = \"Lionel Messi, widely regarded as one of the greatest footballers of all time, has amassed a record seven Ballon d'Or awards throughout his illustrious career and, at 37 years old, continues to be a prominent figure in the world of soccer.\"\n",
    "football_player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A single prompt to extract information from \"football_palyer\" in a JSON format\n",
    "prompt = f\"\"\"\n",
    "Can you extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "age\n",
    "sports\n",
    "awards\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{football_player}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nCan you extract the following information from the given text and return it as a JSON object:\\n\\nname\\nage\\nsports\\nawards\\n\\nThis is the body of text to extract the information from:\\nLionel Messi, widely regarded as one of the greatest footballers of all time, has amassed a record seven Ballon d'Or awards throughout his illustrious career and, at 37 years old, continues to be a prominent figure in the world of soccer.\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate OpenAI Client\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=openai_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt chat completion reponse\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-9p9VhJFW1a7krpFkEbn1vX7rukCHr', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"name\": \"Lionel Messi\",\\n  \"age\": 37,\\n  \"sports\": \"soccer\",\\n  \"awards\": 7\\n}', role='assistant', function_call=None, tool_calls=None))], created=1721978313, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=35, prompt_tokens=101, total_tokens=136))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"name\": \"Lionel Messi\",\\n  \"age\": 37,\\n  \"sports\": \"soccer\",\\n  \"awards\": 7\\n}'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output=response.choices[0].message.content\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display **zero-shot prompt** response in JSON format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Lionel Messi', 'age': 37, 'sports': 'soccer', 'awards': 7}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "json.loads(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Function Calling\n",
    "\n",
    "**Custom Function Calling** refers to the capability of integrating specific, user-defined functions into interactions with language models. This allows you to extend the functionality of the model by enabling it to invoke custom operations or processes based on the input it receives.\n",
    "\n",
    "Breakdown of **`\"name\"`** parameter:\n",
    "\n",
    "| **Attribute**  | **Description**                                                                                       |\n",
    "|----------------|-------------------------------------------------------------------------------------------------------|\n",
    "| **`\"type\"`**   | `\"string\"`: Specifies that the value for `\"name\"` should be a string, indicating it represents text. |\n",
    "| **`\"description\"`** | `\"Name of the player\"`: Provides a brief explanation that this parameter refers to the playerâ€™s name. |\n",
    "| **`\"required\"`** | `[\"name\"]`: Indicates that the `\"name\"` field is mandatory in the output; the function must always include this information. |\n",
    "\n",
    "Below **function call** snippet format is available in [Function Calling Example Section](https://platform.openai.com/docs/guides/function-calling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_function = [\n",
    "    {   \n",
    "        \"name\": \"extract_player_info\",\n",
    "        \"description\": \"Get the player information from the body of input text\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"name\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Name of the player\",\n",
    "                },\n",
    "                \"age\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"Age of the player\",\n",
    "                },\n",
    "                \"sports\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Sports played by the player\",\n",
    "                },\n",
    "                \"awards\": {\n",
    "                    \n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Awards awarded to the player\",\n",
    "                },\n",
    "            },\n",
    "            # \"required\": [\"name\"],\n",
    "        },\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt chat completion reponse using custom function calling\n",
    "custom_func_call_response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }\n",
    "    ],\n",
    "    functions=custom_function\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\"name\":\"Lionel Messi\",\"age\":37,\"sports\":\"football\",\"awards\":\"seven Ballon d\\'Or\"}', name='extract_player_info'), tool_calls=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_func_call_response.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_output = custom_func_call_response.choices[0].message.function_call.arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Lionel Messi',\n",
       " 'age': 37,\n",
       " 'sports': 'football',\n",
       " 'awards': \"seven Ballon d'Or\"}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(custom_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Calls\n",
    "\n",
    "Let's iterate over player information for **function calls**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "football_player2 = \"Cristiano Ronaldo, widely regarded as one of the greatest footballers of all time, has amassed a record five Ballon d'Or awards throughout his illustrious career and, at 39 years old, continues to be a prominent figure in the world of soccer.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "basketball_player = \"Kobe Bryant, widely celebrated as one of the greatest basketball players of all time, won five NBA Championships with the Los Angeles Lakers and earned two NBA Finals MVP awards during his remarkable career. At 41 years old, Bryant remains a legendary figure in the world of basketball, renowned for his skill, work ethic, and competitive spirit.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player Info:\n",
      " {'name': 'Lionel Messi', 'age': 37, 'awards': \"seven Ballon d'Or awards\"}\n",
      "\n",
      "Player Info:\n",
      " {'name': 'Cristiano Ronaldo', 'age': 39, 'awards': \"five Ballon d'Or awards\", 'sports': 'football'}\n",
      "\n",
      "Player Info:\n",
      " {'name': 'Kobe Bryant', 'age': 41, 'sports': 'basketball', 'awards': 'five NBA Championships, two NBA Finals MVP awards'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "players_info = [football_player, football_player2, basketball_player]\n",
    "\n",
    "# Iterate players_info\n",
    "for player in players_info:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": player\n",
    "            }\n",
    "        ],\n",
    "        functions=custom_function,\n",
    "        function_call=\"auto\"\n",
    "    )\n",
    "\n",
    "    response = json.loads(response.choices[0].message.function_call.arguments)\n",
    "    print(f\"Player Info:\\n {response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Function Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_function_2 = [\n",
    "    {   \n",
    "        \"name\": \"extract_player_info\",\n",
    "        \"description\": \"Get the player information from the body of input text\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"name\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Name of the player\",\n",
    "                },\n",
    "                \"awards\": {\n",
    "                    \n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Awards awarded to the player\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"name\"],\n",
    "        },\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player Info (1):\n",
      " {'name': 'Lionel Messi', 'age': 37, 'awards': \"seven Ballon d'Or\"}\n",
      "\n",
      "Player Info (1):\n",
      " {'name': 'Lionel Messi', 'awards': \"seven Ballon d'Or awards\"}\n",
      "\n",
      "Player Info (2):\n",
      " {'name': 'Cristiano Ronaldo', 'age': 39, 'awards': \"five Ballon d'Or awards\", 'sports': 'soccer'}\n",
      "\n",
      "Player Info (2):\n",
      " {'name': 'Cristiano Ronaldo', 'awards': \"five Ballon d'Or awards\"}\n",
      "\n",
      "Player Info (3):\n",
      " {'name': 'Kobe Bryant', 'age': 41, 'sports': 'basketball', 'awards': 'five NBA Championships, two NBA Finals MVP awards'}\n",
      "\n",
      "Player Info (3):\n",
      " {'name': 'Kobe Bryant', 'awards': 'Five NBA Championships, Two NBA Finals MVP awards'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "custom_func = [custom_function, custom_function_2]\n",
    "players_info = [football_player, football_player2, basketball_player]\n",
    "\n",
    "# Iterate players_info\n",
    "for idx, player in enumerate(players_info):\n",
    "    for func in custom_func:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": player\n",
    "                }\n",
    "            ],\n",
    "            functions=func,\n",
    "            function_call=\"auto\"\n",
    "        )\n",
    "\n",
    "        response = json.loads(response.choices[0].message.function_call.arguments)\n",
    "        print(f\"Player Info ({idx+1}):\\n {response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Multiple Function Call\n",
    "\n",
    "![Function Call](https://gradientflow.com/wp-content/uploads/2024/01/newsletter94-function-calling.jpeg)\n",
    "\n",
    "Let's try out using another prompt that is used in **real-life scenario**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a response using prompt that depicts a real life scenario\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages =[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"When's the next flight from Nepal to USA?\"      # Promt\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but as a language model AI, I am unable to provide real-time information or flight schedules. It's best to check with airlines or online booking platforms for the most up-to-date flight schedules and availability.\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the response\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** \n",
    "> - In industry applications, a response like <span style=\"color: green;\">**_\"I'm sorry, ... as an AI language model, I am unable to provide real-time information ...\"_**</span> is not ideal. \n",
    ">\n",
    "> - This limitation arises because OpenAI models are trained on static datasets and do not have access to real-time information or updates. \n",
    ">\n",
    "> - Instead, modern industry-standard chatbots **leverage LLMs to understand the context of the conversation and integrate with third-party APIs or databases**. This approach enables them to provide up-to-date information and perform dynamic actions, showcasing the power and effectiveness of real-time interactions in practical applications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_description_function = [\n",
    "    {\n",
    "        \"name\": \"get_flight_info\",\n",
    "        \"description\": \"Get flight details between two locations\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"loc_origin\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Departure location, eg: NEP\",\n",
    "                },\n",
    "                \"loc_destination\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Arrival location, eg: USA\",\n",
    "                },\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"loc_origin\", \"loc_destination\"]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt Example\n",
    "user_prompt = \"When's the next flight from Nepal to USA?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "advance_prompt = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_prompt\n",
    "        }\n",
    "    ],\n",
    "    # Add function calling\n",
    "    functions=flight_description_function,\n",
    "    # NOTE: This parameter set to \"auto\" indicated the model should automatically determine when to call a function based on the converstion's context\n",
    "    function_call=\"auto\"       \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"loc_origin\":\"NEP\",\"loc_destination\":\"USA\"}'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the response\n",
    "advance_prompt.choices[0].message.function_call.arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Here, the GPT Model has identified the properties that we need based on the prompt.\n",
    "\n",
    "Now, lets **replicate the flight API** by making our own logic using function. If you want actual real-time 3rd aprty API, you can search up **Flight API** in [**RapidAPI**](https://rapidapi.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "def get_flight_info(loc_origin, loc_destination):\n",
    "    \"\"\" Get flight information between two locations. \"\"\"\n",
    "\n",
    "    # Simulate API call\n",
    "    flight_info = {\n",
    "        \"loc_origin\": loc_origin,\n",
    "        \"loc_destination\": loc_destination,\n",
    "        \"datetime\": str(datetime.now() + timedelta(hours=20)),\n",
    "        \"airline\": \"AirAsia\",\n",
    "        \"flight_number\": \"AS123\"\n",
    "    }\n",
    "\n",
    "    return json.dumps(flight_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loc_origin': 'NEP', 'loc_destination': 'USA'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pass response to dictionary\n",
    "params = json.loads(advance_prompt.choices[0].message.function_call.arguments)\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('NEP', 'USA')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin = json.loads(advance_prompt.choices[0].message.function_call.arguments).get(\"loc_origin\")\n",
    "destination = json.loads(advance_prompt.choices[0].message.function_call.arguments).get(\"loc_destination\")\n",
    "\n",
    "origin, destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'get_flight_info'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check `function_call` name\n",
    "advance_prompt.choices[0].message.function_call.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loc_origin': 'NEP',\n",
       " 'loc_destination': 'USA',\n",
       " 'datetime': '2024-07-27 09:50:52.694837',\n",
       " 'airline': 'AirAsia',\n",
       " 'flight_number': 'AS123'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flight_func = eval(advance_prompt.choices[0].message.function_call.name)\n",
    "\n",
    "flight = flight_func(**params)\n",
    "json.loads(flight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's complete the **advanced function calling** and complete extraction of flight information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"When's the next flight from Nepal to USA?\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "advance_prompt2 = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_prompt\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"name\": advance_prompt.choices[0].message.function_call.name,\n",
    "            \"content\": flight\n",
    "        }\n",
    "    ],\n",
    "    functions=flight_description_function,\n",
    "    function_call=\"auto\"       \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The next flight from Nepal to USA is on July 27, 2024 at 09:50 AM. The flight is operated by AirAsia with the flight number AS123.', role='assistant', function_call=None, tool_calls=None))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advance_prompt2.choices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The next flight from Nepal to USA is on July 27, 2024 at 09:50 AM. The flight is operated by AirAsia with the flight number AS123.'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advance_prompt2.choices[0].message.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
