{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hugging Face\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "![ Hugging Face](https://media.licdn.com/dms/image/D5612AQH9oV7fFqFtYg/article-cover_image-shrink_720_1280/0/1707196998403?e=2147483647&v=beta&t=I1CfPU36DXToAl-9YkWTESiTnO9D7WgICP71PIBRtsk)\n",
    "</div>\n",
    "\n",
    "<img src=\"\">\n",
    "\n",
    "Hugging Face is a company and community known for its work in **natural language processing (NLP)** and **machine learning**. It provides a wide range of tools, including the popular **Transformers library**, which offers pre-trained models for tasks like **text classification**, **translation**, **summarization**, and **question-answering**. Hugging Face also supports other **machine learning models** and has an ecosystem that includes **datasets**, **model hubs**, and **development tools**. Their platform fosters **collaboration** and **accessibility** in the AI community, making advanced NLP technologies more widely available.\n",
    "\n",
    "\n",
    "## 00. Getting Started\n",
    "\n",
    "- __Activate virtual env (optional):__ To activate the virtual environment enter this your terminal:\n",
    "\n",
    "```bash\n",
    "      source env/bin/activate\n",
    "```\n",
    "\n",
    "- __Install Hugging Face Tools:__ In order to utilize hugging face tools, install the following packages:\n",
    "\n",
    "```bash\n",
    "      pip3 install huggingface_hub transformers accelerate bitsandbytes\n",
    "```\n",
    "\n",
    "- __Account Setup:__ First, create and [Hugging Face account](https://huggingface.co/join) or [log in](https://huggingface.co/login)\n",
    "\n",
    "- __API Key:__ After signing up, obtain your **Access Token** by navigating to the [`Settings>Access Tokens`](https://huggingface.co/settings/tokens) section.\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "![Access Token](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/hub/new-token-dark.png)\n",
    "</div>\n",
    "\n",
    "> __Note:__ Token Access may require __READ__ and __WRITE__ permissions.\n",
    "\n",
    "- Next, create a `.env` file in the root directory of your project and add your Hugging Face Access Token key:\n",
    "\n",
    "```python\n",
    "HUGGINGFACEHUB_API_TOKEN =\"YOUR_TOKEN\"\n",
    "```\n",
    "\n",
    "> **Note:** Create a `.gitignore` file and add `.env` to it. This will ensure that your __API key__, __Tokens__ and other sensitive information in the `.env` file are not included in version control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "from langchain import PromptTemplate, HuggingFaceHub\n",
    "\n",
    "# Load environment variables form .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access environment variables\n",
    "HUGGINGFACEHUB_API_TOKEN  = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. Overview of Hugging Face Models\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "![Model Overview](https://miro.medium.com/v2/resize:fit:1400/1*hi9dtGyJoe0q2GB33cS3ig.png)\n",
    "</div>\n",
    "\n",
    "Hugging Face offers a diverse range of models across various categories, including:\n",
    "\n",
    "- **Transformers**: State-of-the-art models like **BERT**, **GPT**, **T5**, and **RoBERTa** for tasks such as text classification, translation, summarization, and question-answering.\n",
    "\n",
    "- **Sequence-to-Sequence**: Models like **T5** and **BART** for text generation and translation.\n",
    "\n",
    "- **Token Classification**: Models for named entity recognition (NER) and other token-level tasks.\n",
    "\n",
    "- **Text Generation**: Models like **GPT-3** and **GPT-4** for generating coherent and contextually relevant text.\n",
    "\n",
    "- **Vision Transformers**: Models for image classification and object detection.\n",
    "\n",
    "- **Multimodal Models**: Models that integrate both text and image data for tasks like image captioning and visual question answering.\n",
    "\n",
    "These models are pre-trained and fine-tuned on various datasets, making them versatile for numerous NLP and machine learning applications.\n",
    "\n",
    "### 2.1 [Google Flan T5 Model Large](https://huggingface.co/google/flan-t5-large)\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "![Google Flan T5 Model](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/model_doc/flan2_architecture.jpg)\n",
    "</div>\n",
    "\n",
    "- **Architecture**: Based on T5, handles all tasks as text-to-text (input and output are text).\n",
    "\n",
    "- **Pre-training**: Trained on diverse tasks, fine-tuned with instruction-based data for better task-specific understanding.\n",
    "\n",
    "- **Size**: \"Large\" version has ~770 million parameters; larger versions (e.g., XXL) have even more.\n",
    "\n",
    "- **Capabilities**: Excels at text completion, summarization, translation, and question-answering.\n",
    "\n",
    "- **Use Cases**: Suitable for complex text generation, multi-step reasoning, and tasks requiring detailed instructions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a prompt template\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"product\", \"subject\"],\n",
    "    template=\"What is good name for {product} that has amazing new features\" \n",
    ")\n",
    "\n",
    "# Initialize Hugging Face Model and set temperature\n",
    "model = HuggingFaceHub(repo_id=\"google/flan-t5-large\", \n",
    "                       model_kwargs={\"temperature\":1.5})\n",
    "\n",
    "# Create a chain\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dslr'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate response\n",
    "chain.invoke(\"camera\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'moto g'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"smartphone\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 [Mistral 7B Instruct v0.2](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2)\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "![Model Overview](https://miro.medium.com/v2/resize:fit:1400/1*7sBn0_bwT7_x5Fe3iegqvg.png)\n",
    "</div>\n",
    "\n",
    "\n",
    "- **Architecture**: Mistral-7B-Instruct is based on the Mistral architecture, designed for instruction-following tasks with a focus on understanding and generating text based on specific prompts.\n",
    "\n",
    "- **Pre-training**: Trained on diverse datasets to handle a range of instructions and tasks, enhancing its ability to follow complex directives.\n",
    "\n",
    "- **Size**: Contains 7 billion parameters, balancing high performance with manageable computational requirements.\n",
    "\n",
    "- **Capabilities**: Excels at following detailed instructions, text generation, and performing tasks based on specific user prompts.\n",
    "\n",
    "- **Use Cases**: Suitable for applications requiring precise instruction-following, detailed text generation, and scenarios where complex user inputs are involved.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a prompt template\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"product\", \"subject\"],\n",
    "    template=\"{sentence}. Translate the sentence into spanish language. \\nAnswer should be in this format: \\nPrompt: {sentence}\\nResponse: \" \n",
    ")\n",
    "\n",
    "# Initialize Hugging Face Model and set temperature\n",
    "model = HuggingFaceHub(repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\", \n",
    "                       model_kwargs={\"temperature\":0.7})\n",
    "\n",
    "# Create a chain\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch is the best framework to build deep learning models. Translate the sentence into spanish language. \n",
      "Answer should be in this format: \n",
      "Prompt: PyTorch is the best framework to build deep learning models\n",
      "Response: \n",
      "PyTorch es el mejor marco para construir modelos de aprendizaje profundo.\n"
     ]
    }
   ],
   "source": [
    "# Generate a response\n",
    "print(chain.invoke(\"PyTorch is the best framework to build deep learning models\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
