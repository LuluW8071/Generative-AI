{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain\n",
    "\n",
    "<center>\n",
    "\n",
    "![LangChain](https://www.unite.ai/wp-content/uploads/2023/08/Heisenbergforlife_A_vivid_scene_where_a_striking_green_parrot_a_0607a84e-c5b8-41c7-8c9f-f3d154a0c7c2.png)\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05. Chains\n",
    "\n",
    "#### [Reference Docs](https://python.langchain.com/v0.1/docs/modules/chains/)\n",
    "\n",
    "Central to LangChain is vital-component known as **LangChain Chains**, forming the core connection among one or several large lanaguage models(LLMs). In certain sophisticated applications, it becomes necessary to chain LLMs together, either with each other or with other elements.\n",
    "\n",
    "LangChain provides two high level frameworks for **\"chaining\"** components.\n",
    "- __Chain Interface__\n",
    "\n",
    "- __LangChain Expression Language(LCEL)__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os \n",
    "import openai \n",
    "import langchain\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "# Load environment variables form .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access environment variables and setup OpenAI client\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.api_key = openai_key\n",
    "\n",
    "# Initialize OpenAI LLM client\n",
    "client = OpenAI(openai_api_key=openai_key)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PromptTemplate\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Create PromptTemplate\n",
    "prompt = PromptTemplate.from_template(\n",
    "    input_vairable= [\"product\"],\n",
    "    template = \"Where can I buy {product}? Give the response in a list format.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Types of Framework for Chaining Components\n",
    "\n",
    "#### 5.1.1 Chain Interface\n",
    "\n",
    "> __Deprecated__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luluw/Desktop/LangChain-Generative-AI/env/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# Import LangChain Chain\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(prompt=prompt, llm=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'product': 'Graphic Card Nvidia RTX 4090',\n",
       " 'text': \"\\n\\n1. Nvidia Online Store - The official website of Nvidia offers various RTX 4090 models for purchase directly from the manufacturer.\\n\\n2. Amazon - One of the largest online retailers, Amazon, has a wide selection of Nvidia RTX 4090 graphics cards from different brands and sellers.\\n\\n3. Newegg - Another popular online marketplace for computer hardware, Newegg, has a variety of Nvidia RTX 4090 cards available for purchase.\\n\\n4. Best Buy - This electronics retailer has a decent selection of Nvidia RTX 4090 graphics cards available for purchase both online and in-store.\\n\\n5. Micro Center - A popular destination for computer enthusiasts, Micro Center, offers a range of Nvidia RTX 4090 cards at its physical stores.\\n\\n6. B&H Photo Video - This online retailer specializes in photography and video equipment but also offers a selection of Nvidia RTX 4090 graphics cards.\\n\\n7. Fry's Electronics - Another retail chain specializing in computer hardware, Fry's Electronics, has a selection of Nvidia RTX 4090 cards available for purchase.\\n\\n8. Overclockers UK - A UK-based online retailer, Overclockers UK, offers a variety of Nvidia RTX 4090 cards for purchase with worldwide shipping options.\\n\\n9. Scan -\"}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke(\"Graphic Card Nvidia RTX 4090\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Nvidia Online Store - The official website of Nvidia offers various RTX 4090 models for purchase directly from the manufacturer.\n",
      "\n",
      "2. Amazon - One of the largest online retailers, Amazon, has a wide selection of Nvidia RTX 4090 graphics cards from different brands and sellers.\n",
      "\n",
      "3. Newegg - Another popular online marketplace for computer hardware, Newegg, has a variety of Nvidia RTX 4090 cards available for purchase.\n",
      "\n",
      "4. Best Buy - This electronics retailer has a decent selection of Nvidia RTX 4090 graphics cards available for purchase both online and in-store.\n",
      "\n",
      "5. Micro Center - A popular destination for computer enthusiasts, Micro Center, offers a range of Nvidia RTX 4090 cards at its physical stores.\n",
      "\n",
      "6. B&H Photo Video - This online retailer specializes in photography and video equipment but also offers a selection of Nvidia RTX 4090 graphics cards.\n",
      "\n",
      "7. Fry's Electronics - Another retail chain specializing in computer hardware, Fry's Electronics, has a selection of Nvidia RTX 4090 cards available for purchase.\n",
      "\n",
      "8. Overclockers UK - A UK-based online retailer, Overclockers UK, offers a variety of Nvidia RTX 4090 cards for purchase with worldwide shipping options.\n",
      "\n",
      "9. Scan -\n"
     ]
    }
   ],
   "source": [
    "print(response[\"text\"].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWhere can I buy Dragonfruit?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Dragonfruit can be purchased at most grocery stores and supermarkets, as well as specialty Asian markets and health food stores. It can also be purchased online from various retailers. Some places to buy dragonfruit include:\n",
      "\n",
      "1. Whole Foods Market\n",
      "2. Trader Joe's\n",
      "3. Safeway\n",
      "4. Walmart\n",
      "5. Kroger\n",
      "6. Asian markets (such as H Mart or 99 Ranch Market)\n",
      "7. Health food stores (such as Sprouts or Natural Grocers)\n",
      "8. Farmers' markets\n",
      "9. Online retailers (such as Amazon or FreshDirect)\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate.from_template(\n",
    "    input_variable=[\"product\"],\n",
    "    template=\"Where can I buy {product}?\"\n",
    "    )\n",
    "\n",
    "# Setting verbose=True displays the detailed happenings in background\n",
    "chain = LLMChain(llm=client, prompt=prompt, verbose=True)\n",
    "\n",
    "response_1 = chain.invoke(\"Dragonfruit\")\n",
    "print(response_1[\"text\"].strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.2 LangChain Expression Language(LCEL)\n",
    "\n",
    "**LCEL** is a declarative way to easily compose chains together. There are several benifits to writing chains in this manner as it allows for easy chaining of different components using **`|`** operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import json\n",
    "from langchain.schema import BaseOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "class LLMOutputToJsonParser(BaseOutputParser):\n",
    "    \"\"\" Parse the output of an LLM call to a JSON format \"\"\"\n",
    "\n",
    "    def parse(self, text: str) -> dict:\n",
    "        countries = []\n",
    "        lines = text.split(\"\\n\")\n",
    "\n",
    "        for line in lines:\n",
    "            parts = line.split('. ')\n",
    "            if len(parts)>1:\n",
    "                country_name = parts[1]\n",
    "                countries.append(country_name)\n",
    "\n",
    "        # Create a dict containing the countries \n",
    "        output_dict = {f\"country{i+1}\": country for i, country in enumerate(countries)}\n",
    "\n",
    "        # Return after dict to a JSON string conversion\n",
    "        return json.dumps(output_dict, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"country1\": \"Some of the largest importers of rice include China, Nigeria, Iran, Saudi Arabia, Indonesia, and the Philippines\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "model = OpenAI(openai_api_key=openai_key)  \n",
    "prompt = PromptTemplate.from_template(\n",
    "    template=\"Where countries import {product}?\"\n",
    "    )\n",
    "\n",
    "# Chain the output parser, model and prompt using LCEL\n",
    "chain = prompt | model | LLMOutputToJsonParser()\n",
    "output = chain.invoke({\"product\": \"rice\"})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.1.2.1 Stream, Batch and Async support in LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# Create a prompt template and chain the prompt with model\n",
    "model = OpenAI(openai_api_key=openai_key, max_tokens=256)  \n",
    "prompt = ChatPromptTemplate.from_template(\"Tell me about first ever successful {topic} in small paragraph\")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Streaming__ allows you to receive the output of a chian in chunks rather tha waiting for the entire output to be generated. This can be useful for processing large amounts of data or for real-time applications. To use streaming, __`.stream`__ method on a chain can be used.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "On December 21, 2015, history was made as SpaceX successfully landed its Falcon 9 rocket for the first time. The rocket had just delivered 11 satellites into orbit for the telecommunications company, Orbcomm, and then made a controlled descent back to Earth. The landing took place at SpaceX's Landing Zone 1 at Cape Canaveral, Florida, where the rocket gracefully touched down on its landing legs. This was a monumental achievement as it marked the first time a rocket had ever been launched into orbit and then safely returned to land vertically. This successful landing marked a major milestone for SpaceX's goal of creating reusable rockets, reducing the cost of space travel, and ultimately making space exploration more accessible for all."
     ]
    }
   ],
   "source": [
    "# Streaming\n",
    "for s in chain.stream({\"topic\": \"landing of Falcon Rocket by SpaceX\"}):\n",
    "    print(s, end=\"\", flush=\"True\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Batching__ allows you to process multiple inputs at once, which can be more efficient than processing them by one by one. To batch inputs, `.batch` method on a chain can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Tell me about first ever successful landing of Falcon Rocket by SpaceX in small paragraph\n",
      "Output: \n",
      "\n",
      "On December 21, 2015, SpaceX made history by successfully landing the first stage of their Falcon 9 rocket back on Earth. This was a major milestone for the company, as it was the first time a rocket had ever been successfully landed after launching into orbit. The Falcon 9 had just delivered 11 satellites into space for the ORBCOMM-2 mission, and then made a controlled descent back to Earth. The rocket landed vertically on a landing pad at Cape Canaveral, Florida, marking a significant achievement for SpaceX and the future of space exploration. This successful landing demonstrated the potential for reusable rockets, which could greatly reduce the cost of space missions and make space travel more accessible. This accomplishment solidified SpaceX's position as a leader in the commercial space industry and paved the way for future successful landings and advancements in space technology.\n",
      "\n",
      "Prompt: Tell me about first ever successful detection of ripple in fabric of space-time due to two blackholes merger in small paragraph\n",
      "Output: \n",
      "\n",
      "In September 2015, the Laser Interferometer Gravitational-Wave Observatory (LIGO) made history by detecting the first ever gravitational wave caused by the merger of two black holes. This groundbreaking discovery confirmed a major prediction of Albert Einstein's theory of general relativity and opened up a new window into the study of the universe. The detection was made possible by two LIGO detectors, which use laser beams to measure minuscule changes in the distance between two mirrors. The ripples in space-time caused by the black hole merger were so tiny that they were only able to be detected by this incredibly sensitive equipment. This detection not only provided evidence for the existence of gravitational waves, but also gave scientists a new tool for studying the most extreme and mysterious objects in the universe. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Batching\n",
    "batch_prompts = [{\"topic\": \"landing of Falcon Rocket by SpaceX\"},\n",
    "                 {\"topic\": \"detection of ripple in fabric of space-time due to two blackholes merger\"}]\n",
    "                 \n",
    "outputs = chain.batch(batch_prompts)\n",
    "\n",
    "# Display the outputs\n",
    "for i, result in enumerate(outputs):\n",
    "    formatted_prompt = prompt.messages[0].prompt.template.format(topic=batch_prompts[i]['topic'])\n",
    "    print(f\"Prompt: {formatted_prompt}\")\n",
    "    print(f\"Output: {result}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Async__ support allows you to invoke chains asynchronously, which can be useful for handling concurrent requests or for integrating with other async code. To invoke a chain asynchronously,\n",
    "\n",
    "    - __`.ainvoke`__ method can be used for single invocations, \n",
    "\n",
    "    - __`.abatch`__ method can be used for batching and \n",
    "    \n",
    "    - __`.astream`__ method for streaming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# async\n",
    "async def async_invoke():\n",
    "    # Single invocation\n",
    "    response = await chain.ainvoke({\"topic\": \"landing of Falcon Rocket by SpaceX\"})\n",
    "    print(response)\n",
    "\n",
    "    # Batching\n",
    "    batch_prompts = [{\"topic\": \"landing of Falcon Rocket by SpaceX\"},\n",
    "                 {\"topic\": \"detection of ripple in fabric of space-time due to two blackholes merger\"}]\n",
    "                 \n",
    "    responses = await chain.abatch(batch_prompts)\n",
    "\n",
    "    # Display the outputs\n",
    "    for i, result in enumerate(responses):\n",
    "        formatted_prompt = prompt.messages[0].prompt.template.format(topic=batch_prompts[i]['topic'])\n",
    "        print(f\"Prompt: {formatted_prompt}\")\n",
    "        print(f\"Output: {result}\\n\")\n",
    "\n",
    "    # Streaming\n",
    "    async for s in chain.astream({\"topic\": \"landing of Falcon Rocket by SpaceX\"}):\n",
    "        print(s, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "On December 21, 2015, SpaceX made history with the first ever successful landing of their Falcon 9 rocket. The rocket had launched from Cape Canaveral Air Force Station in Florida with 11 satellites for the telecommunications company Orbcomm. After the successful launch, the first stage of the rocket separated and began its descent back to Earth. Using a series of maneuvers and engine burns, the rocket was able to make a controlled landing on a landing pad at Cape Canaveral, marking the first time a rocket had ever landed intact after reaching orbit. This achievement was a major milestone for SpaceX and the space industry as a whole, as it proved the viability of reusable rockets and opened up possibilities for more cost-effective and sustainable space travel. \n",
      "Prompt: Tell me about first ever successful landing of Falcon Rocket by SpaceX in small paragraph\n",
      "Output: \n",
      "\n",
      "On December 21, 2015, history was made when SpaceX successfully landed their Falcon 9 rocket at Cape Canaveral Air Force Station in Florida. This was the first time in history that a rocket had been launched into space and then returned to Earth intact and upright. This groundbreaking achievement marked a major milestone in space exploration and brought SpaceX one step closer to their goal of creating reusable spacecraft. The Falcon 9 rocket had been carrying 11 satellites for the communications company Orbcomm before returning to Earth, making it the first time a commercial satellite had been launched and landed successfully. This successful landing proved that reusable rockets are not only possible but also economically viable for future space missions. The event was celebrated worldwide and solidified SpaceX's position as a leading innovator in the space industry.\n",
      "\n",
      "Prompt: Tell me about first ever successful detection of ripple in fabric of space-time due to two blackholes merger in small paragraph\n",
      "Output: \n",
      "\n",
      "In 2015, the Laser Interferometer Gravitational-Wave Observatory (LIGO) made the first ever successful detection of a gravitational wave, confirming a major prediction of Albert Einstein's theory of general relativity. The gravitational wave was caused by the merger of two black holes, each about 30 times the mass of the sun, and was detected by observing tiny ripples in the fabric of space-time. This groundbreaking discovery not only provided the first direct evidence of the existence of gravitational waves, but also opened up a new window for studying the universe, allowing scientists to observe and understand events that were previously invisible. It marked the beginning of a new era in astronomy, where gravitational waves could be used to probe the most extreme and mysterious objects in the universe, such as black holes and neutron stars. \n",
      "\n",
      "\n",
      "\n",
      "The first ever successful landing of a Falcon rocket by SpaceX occurred on December 21, 2015. The Falcon 9 rocket had just delivered 11 satellites into orbit for the company Orbcomm. After completing its primary mission, the rocket re-entered Earth's atmosphere and attempted to land on a floating platform in the Atlantic Ocean. This was a significant milestone for SpaceX, as it was the first time a rocket had successfully landed after being launched to space. Previous attempts had either failed or resulted in the destruction of the rocket upon landing. The success of this landing demonstrated SpaceX's ability to reuse rockets, making space travel more cost-effective and sustainable. It also marked a major step towards the company's goal of making space travel more accessible and affordable for the general public. "
     ]
    }
   ],
   "source": [
    "await async_invoke()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Various ways of Chaining "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "\n",
    "# Initiate OpenAI LLM model\n",
    "model = OpenAI(temperature=0.7, max_tokens=128) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1 Sequential Chains\n",
    "\n",
    "A __sequential chain__ combines multiple chains where the output of one chain is the input of next chain. It runs a sequence of chains one after another. This is particularly useful when you want take the output from one call and use ir as the input to another.\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"https://av-eks-lekhak.s3.amazonaws.com/media/__sized__/article_images/5_83DdPYD-thumbnail_webp-600x300.webp\" alt=\"LangChain Chains\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.1.1 Sequential Chain with Chain Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First prompt\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to a describe a company that makes {product}?\"\n",
    ")\n",
    "\n",
    "# Create first chain\n",
    "chain_one = LLMChain(llm=model, prompt=first_prompt)\n",
    "\n",
    "# Second prompt\n",
    "second_prompt = PromptTemplate.from_template(\n",
    "    template=\"What are the key strengths and unique selling points of {company}?\"\n",
    ")\n",
    "\n",
    "# Create second chain\n",
    "chain_two = LLMChain(llm=model, prompt=second_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m\n",
      "\n",
      "\"CyberTime\" or \"TechWrist\" \u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m\n",
      "\n",
      "1. Cutting-edge Technology: Both CyberTime and TechWrist are equipped with the latest and most advanced technology, providing users with a seamless and efficient experience. This includes features such as AI assistants, voice control, and advanced tracking capabilities.\n",
      "\n",
      "2. Sleek and Stylish Design: Both CyberTime and TechWrist are designed with a modern and sleek aesthetic, making them not only functional but also fashionable. This appeals to a wide range of users, from tech-savvy individuals to fashion-forward consumers.\n",
      "\n",
      "3. Versatility: Both products offer a wide range of features and functions, making them versatile and suitable for various purposes.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'smartwatch', 'output': '\\n\\n1. Cutting-edge Technology: Both CyberTime and TechWrist are equipped with the latest and most advanced technology, providing users with a seamless and efficient experience. This includes features such as AI assistants, voice control, and advanced tracking capabilities.\\n\\n2. Sleek and Stylish Design: Both CyberTime and TechWrist are designed with a modern and sleek aesthetic, making them not only functional but also fashionable. This appeals to a wide range of users, from tech-savvy individuals to fashion-forward consumers.\\n\\n3. Versatility: Both products offer a wide range of features and functions, making them versatile and suitable for various purposes.'}\n"
     ]
    }
   ],
   "source": [
    "# Create simple sequential chain\n",
    "sequential_chain = SimpleSequentialChain(chains=[chain_one, chain_two],\n",
    "                                         verbose=True)\n",
    "\n",
    "# Invoke the sequential chain\n",
    "response = sequential_chain.invoke(\"smartwatch\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Cutting-edge Technology: Both CyberTime and TechWrist are equipped with the latest and most advanced technology, providing users with a seamless and efficient experience. This includes features such as AI assistants, voice control, and advanced tracking capabilities.\n",
      "\n",
      "2. Sleek and Stylish Design: Both CyberTime and TechWrist are designed with a modern and sleek aesthetic, making them not only functional but also fashionable. This appeals to a wide range of users, from tech-savvy individuals to fashion-forward consumers.\n",
      "\n",
      "3. Versatility: Both products offer a wide range of features and functions, making them versatile and suitable for various purposes.\n"
     ]
    }
   ],
   "source": [
    "print(response['output'].strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.1.2 Sequential Chain with LCEL Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First prompt\n",
    "learning_prompt = PromptTemplate(\n",
    "    input_variables=[\"activity\"],\n",
    "    template=\"I want to learn how to {activity}. Can you suggest how I can learn this step-by-step?\"\n",
    ")\n",
    "\n",
    "# Second Prompt\n",
    "time_prompt = PromptTemplate(\n",
    "    input_variables=[\"learning_plan\"],\n",
    "    template=\"I only have one week. Can you create a concise plan to help me hit this goal: {learning_plan}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", api_key=openai_key)\n",
    "\n",
    "# Complete the sequential chain with LCEL\n",
    "seq_chain = ({\"activities\": destination_prompt | llm | StrOutputParser()}\n",
    "    | activities_prompt    \n",
    "    | llm    \n",
    "    | StrOutputParser())\n",
    "\n",
    "# Call the chain\n",
    "print(seq_chain.invoke({\"activity\": \"play the harmonica\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.2 Router Chains\n",
    "\n",
    "A __router chain__ is used for complicated tasks. If we have multiple subchains, each of which is specialized for a particular type of input, we could have a router chain that decides which subchain to pass the input to.\n",
    "\n",
    "#### 5.2.2.1 Router Chain Components\n",
    "\n",
    "1. **Router Chain**: Manages and directs the flow to appropriate destination chains based on input or conditions.\n",
    "\n",
    "2. **Destination Chains**: Specific chains that handle different tasks or functionalities.\n",
    "\n",
    "3. **Default Chain**: A fallback option used when no specific destination chain is selected.\n",
    "\n",
    "</br>\n",
    "<div align=\"center\">\n",
    "    <img src=\"https://av-eks-lekhak.s3.amazonaws.com/media/__sized__/article_images/9_yeEjVhG-thumbnail_webp-600x300.webp\" alt=\"LangChain Chains\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser\n",
    "\n",
    "# Initiate OpenAI LLM model\n",
    "model = OpenAI(temperature=0.7, max_tokens=128) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Role-play Prompting\n",
    "physics_template = \"\"\"You are a very smart physics professor. \\\n",
    "You are great at answering questions about physics in a concise\\\n",
    "and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit\\\n",
    "that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "math_template = \"\"\"You are a very good mathematician. \\\n",
    "You are great at answering math questions. \\\n",
    "You are so good because you are able to break down \\\n",
    "hard problems into their component parts,\n",
    "answer the component parts, and then put them together\\\n",
    "to answer the broader question.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "history_template = \"\"\"You are a very good historian. \\\n",
    "You have an excellent knowledge of and understanding of people,\\\n",
    "events and contexts from a range of historical periods. \\\n",
    "You have the ability to think, reflect, debate, discuss and \\\n",
    "evaluate the past. You have a respect for historical evidence\\\n",
    "and the ability to make use of it to support your explanations \\\n",
    "and judgements.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the prompt templates\n",
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"physics\",\n",
    "        \"description\": \"Good for answering questions about physics\",\n",
    "        \"prompt_template\": physics_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"math\",\n",
    "        \"description\": \"Good for answering math questions\",\n",
    "        \"prompt_template\": math_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"history\",\n",
    "        \"description\": \"Good for answering questions about history\",\n",
    "        \"prompt_template\": history_template\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Destination Chain__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a destination chain\n",
    "destination_chains = {}\n",
    "\n",
    "for info in prompt_infos:\n",
    "    name = info[\"name\"]\n",
    "    prompt_template = info[\"prompt_template\"]\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
    "    chain = LLMChain(llm=model, prompt=prompt)\n",
    "    destination_chains[name] = chain\n",
    "\n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Multi-prompt Router Template__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"Given a raw text input to a \\\n",
    "language model select the model prompt best suited for the input. \\\n",
    "You will be given the names of the available prompts and a \\\n",
    "description of what the prompt is best suited for. \\\n",
    "You may also revise the original input if you think that revising\\\n",
    "it will ultimately lead to a better response from the language model.\n",
    "\n",
    "<< FORMATTING >>\n",
    "Return a markdown code snippet with a JSON object formatted to look like:\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
    "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
    "}}}}\n",
    "```\n",
    "\n",
    "REMEMBER: \"destination\" MUST be one of the candidate prompt \\\n",
    "names specified below OR it can be \"DEFAULT\" if the input is not\\\n",
    "well suited for any of the candidate prompts.\n",
    "REMEMBER: \"next_inputs\" can just be the original input \\\n",
    "if you don't think any modifications are needed.\n",
    "\n",
    "<< CANDIDATE PROMPTS >>\n",
    "{destinations}\n",
    "\n",
    "<< INPUT >>\n",
    "{{input}}\n",
    "\n",
    "<< OUTPUT (remember to include the ```json)>> \\\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Default Chain__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a router prompt and chaining\n",
    "default_prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
    "default_chain = LLMChain(llm=model, prompt=default_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Router Template__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a router template and chain\n",
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(destinations=destinations_str)\n",
    "\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser()\n",
    ")\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(llm=model, prompt=router_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Chaining Everything Together__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "physics: {'input': 'What is a blackhole?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is a blackhole?',\n",
       " 'text': '\\n\\nA black hole is a region of space where the gravitational pull is so strong that nothing, including light, can escape from it. It is formed when a massive star collapses under its own gravity after running out of nuclear fuel. The gravitational pull of a black hole is so strong because all of the mass of the star is compressed into a very small space, creating a massive curvature in space-time. This extreme curvature is what gives a black hole its strong gravitational pull.'}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chaining Everything Together\n",
    "chain = MultiPromptChain(\n",
    "    router_chain=router_chain,\n",
    "    destination_chains=destination_chains,\n",
    "    default_chain=default_chain,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Invoke the chain for physics\n",
    "response = chain.invoke(\"What is a blackhole?\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A black hole is a region of space where the gravitational pull is so strong that nothing, including light, can escape from it. It is formed when a massive star collapses under its own gravity after running out of nuclear fuel. The gravitational pull of a black hole is so strong because all of the mass of the star is compressed into a very small space, creating a massive curvature in space-time. This extreme curvature is what gives a black hole its strong gravitational pull.\n"
     ]
    }
   ],
   "source": [
    "print(response['text'].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "history: {'input': 'When did first World War happen?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Invoke the chain for history related\n",
    "history_response = chain.invoke(\"When did first World War happen?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The First World War, also known as the Great War, took place from July 28, 1914 to November 11, 1918.\n"
     ]
    }
   ],
   "source": [
    "print(history_response['text'].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "None: {'input': 'You are an expert in physics, math, and history. Your task is to provide a detailed response that integrates these disciplines. Consider the following question: How did the development of radar during World War II influence mathematical modeling and physical theories? Make sure to cover: 1. The historical context and significance of the event. 2. The scientific principles and physical theories related to the event. 3. The mathematical modeling and calculations influenced by the event. Provide a comprehensive answer that connects these aspects seamlessly.'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Invoke for both phyiscs, math and  history related\n",
    "combined_prompt = \"\"\"You are an expert in physics, math, and history. \\\n",
    "Your task is to provide a detailed response that integrates these disciplines. Consider the following question:\n",
    "\n",
    "{question}\n",
    "\n",
    "Make sure to cover:\n",
    "1. The historical context and significance of the event.\n",
    "2. The scientific principles and physical theories related to the event.\n",
    "3. The mathematical modeling and calculations influenced by the event.\n",
    "\n",
    "Provide a comprehensive answer that connects these aspects seamlessly.\"\"\"\n",
    "\n",
    "question = \"How did the development of radar during World War II influence mathematical modeling and physical theories?\"\n",
    "\n",
    "combined_response = chain.invoke(combined_prompt.format(question=question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The development of radar during World War II had a significant impact on both mathematical modeling and physical theories. It was a pivotal moment in history that not only revolutionized warfare, but also advanced our understanding of electromagnetism and paved the way for modern radar technology.\n",
      "\n",
      "Firstly, let's provide some historical context. Prior to World War II, scientists had already established the principles of electromagnetism, including the propagation of electromagnetic waves and the concept of resonance. However, it was not until the war that these principles were put into practice and perfected in the form of radar technology. Radar, or Radio Detection And Ranging, was initially developed\n"
     ]
    }
   ],
   "source": [
    "print(combined_response['text'].strip())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
