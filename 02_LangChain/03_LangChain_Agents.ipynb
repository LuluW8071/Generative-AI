{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a1f6ca9",
   "metadata": {},
   "source": [
    "# Introduction to LangChain Agents\n",
    "\n",
    "### What are agents?\n",
    "\n",
    "LLM Agents are AI systems that combine LLMs with modules like planning and memory to handle complex tasks. The LLM acts as the \"brain\", controlling operations to complete a task or user request.\n",
    "\n",
    "Similalry in LangChain, agents use LLMs to determine actions. Agents often use tools, which are functionas called bu the agent to interact with the system. These tools can be high-level utilities to transform inputs, or they can be task-specific. Agents can even use chains and other agents as tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1112a55",
   "metadata": {},
   "source": [
    "## Types of AI Agents\n",
    "\n",
    "### ðŸ¤– Classical Types of AI Agents\n",
    "\n",
    "| Agent Type               | Description                                                                 | Internal State | Goal-Oriented | Utility-Based | Learns |\n",
    "|--------------------------|-----------------------------------------------------------------------------|----------------|----------------|----------------|--------|\n",
    "| **Simple Reflex Agent**      | Acts only on current percepts using condition-action rules.                  | âŒ              | âŒ              | âŒ              | âŒ      |\n",
    "| **Model-Based Reflex Agent**| Uses an internal model to handle partially observable environments.         | âœ…              | âŒ              | âŒ              | âŒ      |\n",
    "| **Goal-Based Agent**         | Selects actions based on achieving a specific goal.                         | âœ…              | âœ…              | âŒ              | âŒ      |\n",
    "| **Utility-Based Agent**      | Chooses between goals/actions based on desirability (utility function).     | âœ…              | âœ…              | âœ…              | âŒ      |\n",
    "| **Learning Agent**           | Learns from experience to improve future performance.                       | âœ…              | âœ…              | âœ…              | âœ…      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1587d8e",
   "metadata": {},
   "source": [
    "### ðŸ¤– ReAct Agents\n",
    "\n",
    "![React agent](https://www.ibm.com/content/dam/connectedassets-adobe-cms/worldwide-content/creative-assets/s-migr/ul/g/ca/0d/react.component.xl.ts=1746190591143.png/content/adobe-cms/us/en/think/topics/react-agent/jcr:content/root/table_of_contents/body-article-8/image)\n",
    "\n",
    "**ReAct** are modern type of intelligent agent which combine two utilties **Re**asoning and **Act**ing, it reasons via Chain-of-Thought process and acts through usage of provided tools. It prompts the model using repeated loop of thinking, acting and observing.  \n",
    "\n",
    "#### âœ¨ Key Features\n",
    "- **Chain-of-Thought Reasoning:** The agent reasons step-by-step like a human would.\n",
    "\n",
    "- **Tool Use:** It can take actions such as running a search, calling an API, or querying a database.\n",
    "- **Memory of Previous Steps:** The agent tracks past reasoning and actions to guide the next move.\n",
    "- **Dynamic Decision Making:** It chooses between thinking more, acting, or giving a final answer.\n",
    "\n",
    "#### ðŸ“Œ How It Works\n",
    "A typical ReAct agent loop:\n",
    "\n",
    "1. **Receives a user query**\n",
    "\n",
    "2. **Thinks**: generates reasoning text\n",
    "3. **Acts**: calls a tool (e.g., search, calculator)\n",
    "4. **Observes**: receives tool output\n",
    "5. **Thinks again** based on observation\n",
    "6. **Repeats** until a final answer is given\n",
    "\n",
    "**ReAct Agents** have tons of applications in real world. Some of them are:\n",
    "\n",
    "- Customer support bots\n",
    "\n",
    "- Educational Tutor\n",
    "\n",
    "- Data Analysis Assistants\n",
    "\n",
    "- Fitness Coaches\n",
    "\n",
    "- AI Coding Assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6055dc",
   "metadata": {},
   "source": [
    "### [LangGraph](https://langchain-ai.github.io/langgraph/)\n",
    "\n",
    "To implement agents, LangGraph is used. It is branch of the LangChain ecosystem specifically for designing agentic systems, or system including agents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c00902e",
   "metadata": {},
   "source": [
    "#### 1. Wikipedia Agent\n",
    "\n",
    "Integrating a Wikipedia agent with LangChain enables users to access vast amounts of information from Wikepedia using natural langauge queries. This can be particularly useful for tasks such as research, fact-checking, andeducational purposes where comprehensive and reliable information is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07ad4ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv()\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "120d6e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wikipedia\n",
      "A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_community.agent_toolkits.load_tools import load_tools\n",
    "\n",
    "# Call the LLM\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
    "\n",
    "# Define tools\n",
    "tools = load_tools([\"wikipedia\"])\n",
    "print(tools[0].name, \n",
    "      tools[0].description, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c659d0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is transformer in deep learning and when was attention is all you need paper published?', additional_kwargs={}, response_metadata={}, id='33d5aa53-d8e0-47ed-9df6-dd72a2e4e263'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'wikipedia', 'arguments': '{\"query\": \"Attention Is All You Need\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--d7d2d12e-6028-4b6a-ac40-50e37697878e-0', tool_calls=[{'name': 'wikipedia', 'args': {'query': 'transformer deep learning'}, 'id': 'b31f771c-98a2-4d5d-9a4c-92a77d8bff94', 'type': 'tool_call'}, {'name': 'wikipedia', 'args': {'query': 'Attention Is All You Need'}, 'id': 'da9db4e1-3a84-4419-b061-d734a6c9cc14', 'type': 'tool_call'}], usage_metadata={'input_tokens': 65, 'output_tokens': 12, 'total_tokens': 77, 'input_token_details': {'cache_read': 0}}),\n",
       "  ToolMessage(content='Page: Transformer (deep learning architecture)\\nSummary: The transformer is a deep learning architecture that was developed by researchers at Google and is based on the multi-head attention mechanism, which was proposed in the 2017 paper \"Attention Is All You Need\". Text is converted to numerical representations called tokens, and each token is converted into a vector via lookup from a word embedding table. At each layer, each token is then contextualized within the scope of the context window with other (unmasked) tokens via a parallel multi-head attention mechanism, allowing the signal for key tokens to be amplified and less important tokens to be diminished.\\nTransformers have the advantage of having no recurrent units, therefore requiring less training time than earlier recurrent neural architectures (RNNs) such as long short-term memory (LSTM). Later variations have been widely adopted for training large language models (LLM) on large (language) datasets.\\n\\nTransformers were first developed as an improvement over previous architectures for machine translation, but have found many applications since. They are used in large-scale natural language processing, computer vision (vision transformers), reinforcement learning, audio, multimodal learning, robotics, and even playing chess. It has also led to the development of pre-trained systems, such as generative pre-trained transformers (GPTs) and BERT (bidirectional encoder representations from transformers).\\n\\n\\n\\nPage: Generative pre-trained transformer\\nSummary: A generative pre-trained transformer (GPT) is a type of large language model (LLM) and a prominent framework for generative artificial intelligence. It is an artificial neural network that is used in natural language processing by machines. It is based on the transformer deep learning architecture, pre-trained on large data sets of unlabeled text, and able to generate novel human-like content. As of 2023, most LLMs had these characteristics and are sometimes referred to broadly as GPTs.\\nThe first GPT was introduced in 2018 by OpenAI. OpenAI has released significant GPT foundation models that have been sequentially numbered, to comprise its \"GPT-n\" series. Each of these was significantly more capable than the previous, due to increased size (number of trainable parameters) and training. The most recent of these, GPT-4o, was released in May 2024. Such models have been the basis for their more task-specific GPT systems, including models fine-tuned for instruction followingâ€”which in turn power the ChatGPT chatbot service.\\nThe term \"GPT\" is also used in the names and descriptions of such models developed by others. For example, other GPT foundation models include a series of models created by EleutherAI, and seven models created by Cerebras in 2023. Companies in different industries have developed task-specific GPTs in their respective fields, such as Salesforce\\'s \"EinsteinGPT\" (for CRM) and Bloomberg\\'s \"BloombergGPT\" (for finance).\\n\\n\\n\\nPage: Attention (machine learning)\\nSummary: Attention is a machine learning method that determines the importance of each component in a sequence relative to the other components in that sequence. In natural language processing, importance is represented by \"soft\" weights assigned to each word in a sentence. More generally, attention encodes vectors called token embeddings across a fixed-width sequence that can range from tens to millions of tokens in size.\\nUnlike \"hard\" weights, which are computed during the backwards training pass, \"soft\" weights exist only in the forward pass and therefore change with every step of the input. Earlier designs implemented the attention mechanism in a serial recurrent neural network (RNN) language translation system, but a more recent design, namely the transformer, removed the slower sequential RNN and relied more heavily on the faster parallel attention scheme.\\nInspired by ideas about attention in humans, the attention mechanism was developed to address the weak', name='wikipedia', id='a414c60b-9aff-4f49-ad47-85cb781b1c71', tool_call_id='b31f771c-98a2-4d5d-9a4c-92a77d8bff94'),\n",
       "  ToolMessage(content='Page: Attention Is All You Need\\nSummary: \"Attention Is All You Need\" is a 2017 landmark research paper in machine learning authored by eight scientists working at Google. The paper introduced a new deep learning architecture known as the transformer, based on the attention mechanism proposed in 2014 by Bahdanau et al. It is considered a foundational paper in modern artificial intelligence, and a main contributor to the AI boom, as the transformer approach has become the main architecture of a wide variety of AI, such as large language models. At the time, the focus of the research was on improving Seq2seq techniques for machine translation, but the authors go further in the paper, foreseeing the technique\\'s potential for other tasks like question answering and what is now known as multimodal Generative AI.\\nThe paper\\'s title is a reference to the song \"All You Need Is Love\" by the Beatles. The name \"Transformer\" was picked because Jakob Uszkoreit, one of the paper\\'s authors, liked the sound of that word.\\nAn early design document was titled \"Transformers: Iterative Self-Attention and Processing for Various Tasks\", and included an illustration of six characters from the Transformers franchise. The team was named Team Transformer.\\nSome early examples that the team tried their Transformer architecture on included English-to-German translation, generating Wikipedia articles on \"The Transformer\", and parsing. These convinced the team that the Transformer is a general purpose language model, and not just good for translation.\\nAs of 2025, the paper has been cited more than 173,000 times, placing it among top ten most-cited papers of the 21st century.\\n\\n\\n\\nPage: All You Need Is Kill\\nSummary: All You Need Is Kill is a Japanese science fiction light novel by Hiroshi Sakurazaka with illustrations by Yoshitoshi Abe. The book was published in Japanese by Shueisha under their Super Dash Bunko imprint in December 2004, and was later released in English by Viz Media under their Haikasoru imprint. All You Need Is Kill follows a soldier named Keiji Kiriya, who, after dying in a battle with extraterrestrials, is caught in a time loop that makes him live the same day repeatedly, allowing Kiriya to improve his fighting skills.\\nA manga adaptation, written by Ryosuke Takeuchi and illustrated by Takeshi Obata, was serialized in Shueisha\\'s Weekly Young Jump magazine between January and May 2014 and was also published by Viz Media in its Weekly Shonen Jump magazine. In November 2014, the Viz translation was released in a collected edition that included the entire series. A separate graphic novel adaptation, written by Nick Mamatas and illustrated by Lee Ferguson, was released in North America in May 2014. A live-action film adaptation from director Doug Liman starring Tom Cruise and Emily Blunt, titled Edge of Tomorrow, was released in May 2014. The English-language film tie-in edition of the novel also uses this title. An anime film adaptation produced by Studio 4Â°C has been announced.\\nThe novel was Sakurazaka\\'s breakthrough science fiction novel, earning wide praise from fellow novelists including Yasutaka Tsutsui and ChÅhei Kanbayashi and was entered in contention for the Best Japanese Long Work in the 36th Seiun Awards in 2005.\\n\\n\\n\\nPage: Transformer (deep learning architecture)\\nSummary: The transformer is a deep learning architecture that was developed by researchers at Google and is based on the multi-head attention mechanism, which was proposed in the 2017 paper \"Attention Is All You Need\". Text is converted to numerical representations called tokens, and each token is converted into a vector via lookup from a word embedding table. At each layer, each token is then contextualized within the scope of the context window with other (unmasked) tokens via a parallel multi-head attention mechanism, allowing the signal for key tokens to be amplified and less important tokens to be diminished.\\nTransformers have the advantage of having no recurrent units, ther', name='wikipedia', id='ab6664d1-daa0-4e3c-bf1c-26c7652e52fd', tool_call_id='da9db4e1-3a84-4419-b061-d734a6c9cc14'),\n",
       "  AIMessage(content='The Transformer is a deep learning architecture based on the multi-head attention mechanism. It was introduced in the \"Attention Is All You Need\" paper, which was published in 2017.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--49dbbd7f-7940-400a-bb94-7380843246b4-0', usage_metadata={'input_tokens': 1719, 'output_tokens': 41, 'total_tokens': 1760, 'input_token_details': {'cache_read': 0}})]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the agent\n",
    "agent = create_react_agent(llm, tools)\n",
    "\n",
    "# Invoke the agent\n",
    "response = agent.invoke({\"messages\": [(\"human\", \"What is transformer in deep learning and when was attention is all you need paper published?\")]})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa75b11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Transformer is a deep learning architecture based on the multi-head attention mechanism. It was introduced in the \"Attention Is All You Need\" paper, which was published in 2017.\n"
     ]
    }
   ],
   "source": [
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0015563b",
   "metadata": {},
   "source": [
    "Let's try another example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d5e1389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated population of New York City in 2024 is 8,478,072.\n"
     ]
    }
   ],
   "source": [
    "# Invoke the agent\n",
    "response = agent.invoke({\"messages\": [(\"human\", \"How many people live in New York City?\")]})\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a52b8f",
   "metadata": {},
   "source": [
    "#### 2. Math Agent\n",
    "\n",
    "The integration of LLMs with math-solving capabilities opens up new possibilities for handling complex mathematical queries and calculations. This is particularly usefor for applications in education, research, and data analysis where mathematical precision is crucial.\n",
    "\n",
    "You may require `numexpr` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5dc94d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of sin(30) * cos(60) is 0.25.\n"
     ]
    }
   ],
   "source": [
    "# Define math tools\n",
    "tools = load_tools([\"llm-math\"], llm=llm)\n",
    "\n",
    "# Define agent \n",
    "math_agent = create_react_agent(llm, tools)\n",
    "\n",
    "# Invoke math agent\n",
    "response = math_agent.invoke(\n",
    "    {\n",
    "        \"messages\": [(\"human\", \n",
    "                      \"What is the value of sin(30) * cos(60), where angles are in degrees?\"\n",
    "        )]\n",
    "    }\n",
    ")\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1f1b3c",
   "metadata": {},
   "source": [
    "Similarly lets try out the integration problem and let the `llm-math` solve it.\n",
    "\n",
    "Evaluate the definite integral:\n",
    "\n",
    "$$\n",
    "\\int_0^2 (3x^2 + 2x + 1)\\, dx\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723b70c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The definite integral of the function 3x^2 + 2x + 1 from x = 0 to x = 2 is 14.0.\n"
     ]
    }
   ],
   "source": [
    "response = math_agent.invoke(\n",
    "    {\n",
    "        \"messages\": [(\"human\",\n",
    "                      \"Evaluate the definite integral of the function 3x^2 + 2x + 1 from x=0 to x=2.\"\n",
    "        )]\n",
    "    }\n",
    ")\n",
    "\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdea8ad",
   "metadata": {},
   "source": [
    "There are **tons of pre-built tools** available built by the langchain community. These tools span a wide range of domains such as:\n",
    "\n",
    "* ðŸŒ Web Searching\n",
    "\n",
    "* ðŸ’» Code Interpretation\n",
    "* ðŸ•¸ï¸ Web Scraping\n",
    "* ðŸ—ƒï¸ Databases\n",
    "* ðŸ’° Finance\n",
    "* ðŸŽ® Entertainment\n",
    "* ...and many more!\n",
    "\n",
    "You can explore the full list of available tools and their usage in the official LangChain documentation:\n",
    "ðŸ”— [LangChain Tool Integrations](https://python.langchain.com/docs/integrations/tools/)\n",
    "\n",
    "Use these tools to build your own intelligent AI service systems, customized to your domain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f6d095",
   "metadata": {},
   "source": [
    "#### 3. Custom Tool\n",
    "\n",
    "In order to integrate the custom tools with the ReAct agent, we first import `tools` from `langchain_core` and add decorator: `@tool` on top of the custom function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46b77f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "# Define a custom function and make it a tool so agent can use it\n",
    "@tool \n",
    "def financial_report(\n",
    "        company_name: str,\n",
    "        revenue: int,\n",
    "        expenses: int\n",
    ") -> str:\n",
    "    \"\"\" Generate a financial report for a company that calculates net income \"\"\"\n",
    "    net_income = revenue - expenses\n",
    "\n",
    "    report = f\"Financial Report for {company_name}:\\n\"\n",
    "    report += f\"Revenue: ${revenue}\\n\"\n",
    "    report += f\"Expenses: ${expenses}\\n\"\n",
    "    report += f\"Net Income: ${net_income}\"\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f26a998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "financial_report\n",
      "Generate a financial report for a company that calculates net income\n",
      "{'company_name': {'title': 'Company Name', 'type': 'string'}, 'revenue': {'title': 'Revenue', 'type': 'integer'}, 'expenses': {'title': 'Expenses', 'type': 'integer'}}\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(financial_report.name)            # Function name\n",
    "print(financial_report.description)     # docstring\n",
    "print(financial_report.args)            # Arguments passed in the function\n",
    "print(financial_report.return_direct)   # will only be true when agent calls, completes the task during invoke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ac3680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='FinTech generated $10 million revenue with $8 million of costs. Generate a financial report.', additional_kwargs={}, response_metadata={}, id='3730e398-4063-49c8-92c3-cefe3916676b'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'financial_report', 'arguments': '{\"revenue\": 10000000.0, \"company_name\": \"FinTech\", \"expenses\": 8000000.0}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--f00eb5bd-f125-49be-80c5-17231031b8aa-0', tool_calls=[{'name': 'financial_report', 'args': {'revenue': 10000000.0, 'company_name': 'FinTech', 'expenses': 8000000.0}, 'id': '9e1d536a-8b17-40ed-ae64-bae6c28b73a1', 'type': 'tool_call'}], usage_metadata={'input_tokens': 48, 'output_tokens': 12, 'total_tokens': 60, 'input_token_details': {'cache_read': 0}}),\n",
       "  ToolMessage(content='Financial Report for FinTech:\\nRevenue: $10000000\\nExpenses: $8000000\\nNet Income: $2000000', name='financial_report', id='e5b4287f-8a65-44ea-9062-561740731c0e', tool_call_id='9e1d536a-8b17-40ed-ae64-bae6c28b73a1'),\n",
       "  AIMessage(content='OK. I have generated a financial report for FinTech. The revenue is $10000000, expenses are $8000000, and net income is $2000000.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--473e7f77-d477-42f7-8991-652d22055e31-0', usage_metadata={'input_tokens': 105, 'output_tokens': 50, 'total_tokens': 155, 'input_token_details': {'cache_read': 0}})]}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create react agent with custom tool\n",
    "agent = create_react_agent(model=llm, tools=[financial_report])\n",
    "\n",
    "response = agent.invoke({\n",
    "    \"messages\": [(\n",
    "        \"human\",\n",
    "        \"FinTech generated $10 million revenue with $8 million of costs. Generate a financial report.\"\n",
    "    )]\n",
    "})\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "40112275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Financial Report for FinTech:\n",
      "Revenue: $10000000\n",
      "Expenses: $8000000\n",
      "Net Income: $2000000\n",
      "\n",
      "OK. I have generated a financial report for FinTech. The revenue is $10000000, expenses are $8000000, and net income is $2000000.\n"
     ]
    }
   ],
   "source": [
    "print(response[\"messages\"][-2].content, end=\"\\n\\n\")\n",
    "print(response[\"messages\"][-1].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
