{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain\n",
    "\n",
    "<div style=\"display: flex; align-items: center; justify-content: center\">\n",
    "    <img src=\"https://miro.medium.com/v2/resize:fit:1358/1*Xyu6-ddpKUJFEg5e1vrFew.png\" alt=\"LangChain\">\n",
    "</div>\n",
    "\n",
    "**LangChain** is a powerful open-source framework designed to streamline the development of applications leveraging large language models (LLMs). It provides a comprehensive set of tools and abstractions to seamlessly integrate LLMs with diverse data sources, APIs, and external systems, enabling the creation of sophisticated and interactive applications. LangChain focuses on:\n",
    "\n",
    "- **Connecting LLMs to External Tools:** It enables models to interact with APIs, databases, and other data sources, facilitating the retrieval and utilization of real-time information.\n",
    "\n",
    "- **Managing Conversational Context:** The framework excels in maintaining context and managing state across complex interactions, ensuring coherent and contextually relevant conversations.\n",
    "\n",
    "- **Facilitating Custom Logic:** Developers can implement custom logic and workflows, tailoring the behavior of LLMs to meet specific requirements and use cases.\n",
    "\n",
    "- **Accessibility to Various Models:** LangChain supports integration with different LLMs through APIs, including those from HuggingFace and other model providers, while also providing access to private data sources and third-party APIs.\n",
    "\n",
    "Overall, LangChain enhances the capabilities of LLMs by bridging them with external tools and data sources, making it easier to build dynamic and context-aware applications.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00. Getting Started\n",
    "\n",
    "- __Activate virtual env (optional):__ To activate the virtual environment enter this your terminal:\n",
    "\n",
    "```bash\n",
    "      source openai-env/bin/activate\n",
    "```\n",
    "\n",
    "- __Install LangChain:__ To install __langchain__ and __langchain community__ enter the following command on your terminal:\n",
    "\n",
    "```bash\n",
    "      pip3 install langchain langchain-community\n",
    "```\n",
    "\n",
    "> [**Installation Reference Docs**](https://python.langchain.com/v0.1/docs/get_started/installation/)\n",
    "\n",
    "#### What we are going to learn?\n",
    "\n",
    "<div style=\"display: flex; align-items: center; justify-content: center\">\n",
    "\n",
    "![LangChain Usage Applications](https://media.licdn.com/dms/image/D5612AQGHBoBdQAJF_g/article-cover_image-shrink_720_1280/0/1682676410676?e=2147483647&v=beta&t=oih8lN6UMrC8cHDgMdQmIfls9zkmUPNZSAlzkSCJUiA)\n",
    "</div>\n",
    "\n",
    "| **Feature**                  | **Description**                                                                                                                                                         |\n",
    "|------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Using OpenAI via LangChain**  | Learn how to integrate OpenAI's powerful models into your applications using LangChain, which streamlines interactions and enhances functionality through a unified framework. |\n",
    "| **Prompt Methods**           | Understand various types of prompt engineering methods. |\n",
    "| **Prompt Templating**           | Discover how to create and manage reusable prompt templates with LangChain, ensuring consistency and efficiency in generating model responses across various scenarios. |\n",
    "| **Chains**                     | Explore how to build and use chains in LangChain, which allow for the sequential execution of tasks and processing steps, facilitating complex workflows with OpenAI models. |\n",
    "| **Agents**                     | Understand how agents in LangChain can be employed to handle dynamic interactions and adapt to different contexts, leveraging OpenAI models to execute complex decision-making tasks. |\n",
    "| **Memory**                    | Learn how to implement memory in LangChain to retain context and manage state across interactions, allowing for more coherent and contextually aware conversations with OpenAI models. |\n",
    "| **Document Loader**           | Learn how to use LangChain's document loader to ingest, process, and manage large volumes of documents, enabling effective querying and interaction with text-based data. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01. LangChain and OpenAI\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"https://go-skill-icons.vercel.app/api/icons?i=langchain,chatgpt\" alt=\"GenAI\"  height=\"80\"/>\n",
    "  </br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os \n",
    "import openai \n",
    "import langchain\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "# Load environment variables form .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access environment variables and setup OpenAI client\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.api_key = openai_key\n",
    "\n",
    "# Initiate LangChain OpenAI Client\n",
    "# NOTE: The way of setting up OpenAI API client is different on langchain \n",
    "client = OpenAI(openai_api_key=openai_key)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. Prompt Methods\n",
    "\n",
    "### 2.1 Zero-Shot Prompt\n",
    "\n",
    "A **zero-shot prompt** is a type of prompt where you ask a language model to perform a task or answer a question without providing any specific examples or prior training for that particular task. The model is expected to generate a response based on its general understanding and pre-existing knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_prompt = \"\"\"\n",
    "Can you tell me how many human astronauts have landed on the moon? \n",
    "Can you give the names of those astronauts?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAs of 2021, a total of 24 human astronauts have landed on the moon. \\nThe names of those astronauts are:\\n\\n1. Neil Armstrong\\n2. Buzz Aldrin\\n3. Charles Conrad\\n4. Alan Bean\\n5. Alan Shepard\\n6. Edgar Mitchell\\n7. David Scott\\n8. James Irwin\\n9. John Young\\n10. Charles Duke\\n11. Eugene Cernan\\n12. Harrison Schmitt\\n13. Michael Collins\\n14. Richard Gordon\\n15. Stuart Roosa\\n16. Alfred Worden\\n17. Pete Conrad\\n18. Al Bean\\n19. Alan L. Bean\\n20. Gene Cernan\\n21. Charles M. Duke Jr.\\n22. Edgar D. Mitchell\\n23. James B. Irwin\\n24. John W. Young'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.invoke(zero_shot_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of 2021, a total of 12 human astronauts have landed on the moon. \n",
      "\n",
      "The names of those astronauts are:\n",
      "\n",
      "1. Neil Armstrong \n",
      "2. Buzz Aldrin \n",
      "3. Pete Conrad \n",
      "4. Alan Bean \n",
      "5. Alan Shepard \n",
      "6. Edgar Mitchell \n",
      "7. David Scott \n",
      "8. James Irwin \n",
      "9. John Young \n",
      "10. Charles Duke \n",
      "11. Eugene Cernan \n",
      "12. Harrison Schmitt\n"
     ]
    }
   ],
   "source": [
    "print(client.invoke(zero_shot_prompt).strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Few-Shot Prompt\n",
    "\n",
    "A **few-shot prompt** is a type of prompt where you provide the model with a few examples to guide it in generating the desired response. This method helps the model understand the context or format of the response by showing it examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_prompt = \"\"\"\n",
    "Here are some examples of questions and answers:\n",
    "\n",
    "1. Question: Who is the President of the United States?\n",
    "   Answer: Joe Biden is the President of the United States.\n",
    "\n",
    "2. Question: What is the capital of France?\n",
    "   Answer: The capital of France is Paris.\n",
    "\n",
    "Now, based on these examples, answer the following question:\n",
    "Question: How many human astronauts have landed on the moon? \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: A total of twelve human astronauts have landed on the moon.\n"
     ]
    }
   ],
   "source": [
    "print(client.invoke(few_shot_prompt).strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Instruction-Based Prompt\n",
    "\n",
    "An **instruction-based prompt** is a type of prompt where you provide the model with a detailed instruction along with a question or a set of examples to guide it in generating the desired response. This method helps the model understand the context and format of the response by providing explicit instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_prompt = \"\"\"\n",
    "Provide a list of human astronauts who have landed on the moon. Include their names and the mission they were part of.\n",
    "\n",
    "List:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Neil Armstrong - Apollo 11\n",
      "2. Buzz Aldrin - Apollo 11\n",
      "3. Charles \"Pete\" Conrad - Apollo 12\n",
      "4. Alan Bean - Apollo 12\n",
      "5. Alan Shepard - Apollo 14\n",
      "6. Edgar Mitchell - Apollo 14\n",
      "7. David Scott - Apollo 15\n",
      "8. James Irwin - Apollo 15\n",
      "9. John Young - Apollo 16\n",
      "10. Charles Duke - Apollo 16\n",
      "11. Eugene Cernan - Apollo 17\n",
      "12. Harrison Schmitt - Apollo 17\n"
     ]
    }
   ],
   "source": [
    "print(client.invoke(instruction_prompt).strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Contextual Prompt\n",
    "\n",
    "In a **contextual prompt**, you provide additional context or background information to help the model understand the task better. This can be especially useful when dealing with complex or domain-specific questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "contextual_prompt = \"\"\"\n",
    "In the history of space exploration, twelve astronauts have walked on the lunar surface. They were part of NASA's Apollo missions.\n",
    "\n",
    "Based on this context, please answer the following question:\n",
    "How many human astronauts have landed on the moon, each landing year and what are their names?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twelve human astronauts have landed on the moon, each in a different year. Their names are:\n",
      "\n",
      "1. Neil Armstrong (1969)\n",
      "2. Buzz Aldrin (1969)\n",
      "3. Pete Conrad (1969)\n",
      "4. Alan Bean (1969)\n",
      "5. Alan Shepard (1971)\n",
      "6. Edgar Mitchell (1971)\n",
      "7. David Scott (1971)\n",
      "8. James Irwin (1971)\n",
      "9. John Young (1972)\n",
      "10. Charles Duke (1972)\n",
      "11. Gene Cernan (1972)\n",
      "12. Harrison Schmitt (1972)\n"
     ]
    }
   ],
   "source": [
    "print(client.invoke(contextual_prompt).strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Conversational Prompt\n",
    "\n",
    "In a **conversational prompt**, you structure the input as a dialogue to simulate a more natural interaction. This method can be useful for applications that require back-and-forth communication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversational_prompt = \"\"\"\n",
    "User: How many human astronauts have landed on the moon?\n",
    "Assistant: Sure why not. There have been twelve astronauts who have walked on the lunar surface.\n",
    "\n",
    "User: Can you give me their names and through which rocket they landed on?\n",
    "Assistant:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! The astronauts are:\n",
      "\n",
      "1. Neil Armstrong - Apollo 11\n",
      "2. Buzz Aldrin - Apollo 11\n",
      "3. Pete Conrad - Apollo 12\n",
      "4. Alan Bean - Apollo 12\n",
      "5. Alan Shepard - Apollo 14\n",
      "6. Edgar Mitchell - Apollo 14\n",
      "7. David Scott - Apollo 15\n",
      "8. James Irwin - Apollo 15\n",
      "9. John Young - Apollo 16\n",
      "10. Charles Duke - Apollo 16\n",
      "11. Eugene Cernan - Apollo 17\n",
      "12. Harrison Schmitt - Apollo 17\n",
      "\n",
      "All of these astronauts landed on the moon through the Apollo spacecraft.\n"
     ]
    }
   ],
   "source": [
    "print(client.invoke(conversational_prompt).strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Comparative Prompt\n",
    "\n",
    "In a **comparative prompt**, you ask the model to compare or contrast two or more items or concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparative_prompt = \"\"\"\n",
    "Compare the Apollo 11 mission to the Apollo 12 mission. Include 2 important details in short such as the astronauts involved and key achievements.\n",
    "\n",
    "Apollo 11:\n",
    "Apollo 12:\n",
    "Apollo 13:\n",
    "Apollo 17:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apollo 11:\n",
      "- Astronauts: Neil Armstrong, Buzz Aldrin, Michael Collins\n",
      "- Key Achievement: Successfully landed on the moon and Neil Armstrong became the first person to walk on its surface.\n",
      "\n",
      "Apollo 12:\n",
      "- Astronauts: Pete Conrad, Alan Bean, Richard Gordon\n",
      "- Key Achievement: Conducted the second lunar landing and brought back the first color TV camera footage from the moon.\n",
      "\n",
      "Apollo 13:\n",
      "- Astronauts: Jim Lovell, Jack Swigert, Fred Haise\n",
      "- Key Achievement: Despite a near-disastrous malfunction, the crew safely returned to Earth in a demonstration of teamwork and ingenuity.\n",
      "\n",
      "Apollo 17:\n",
      "- Astronauts: Eugene Cernan, Ronald Evans, Harrison Schmitt\n",
      "- Key Achievement: Last manned mission to the moon, with the longest stay on the lunar surface and collection of the most lunar samples.\n"
     ]
    }
   ],
   "source": [
    "print(client.invoke(comparative_prompt).strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Chain of Thought(CoT) Prompt\n",
    "\n",
    "**Chain of Thought (CoT) prompting** is another effective method used to improve the performance of language models by guiding them through a reasoning process. This approach encourages the model to articulate its reasoning step-by-step, which can help in solving complex problems and generating more accurate responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_of_thought_prompt = \"\"\"\n",
    "To calculate the total cost of purchasing several items with different quantities and prices, follow these steps:\n",
    "\n",
    "    Determine the cost for each type of item by multiplying the quantity of the item by its unit price.\n",
    "    Add up the costs for all types of items to find the total expenditure.\n",
    "\n",
    "Here’s the problem:\n",
    "\n",
    "Calculate the total cost for buying the following items:\n",
    "\n",
    "    4 notebooks, each costing $3.75\n",
    "    2 packs of pens, each costing $2.25\n",
    "    5 folders, each costing $1.50\n",
    "\n",
    "Perform the steps outlined to find the total cost.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Determine the cost for each type of item:\n",
      "\n",
      "Notebooks: 4 x $3.75 = $15\n",
      "Pens: 2 x $2.25 = $4.50\n",
      "Folders: 5 x $1.50 = $7.50\n",
      "\n",
      "2. Add up the costs for all types of items:\n",
      "\n",
      "$15 + $4.50 + $7.50 = $27\n",
      "\n",
      "Therefore, the total cost for purchasing 4 notebooks, 2 packs of pens, and 5 folders is $27.\n"
     ]
    }
   ],
   "source": [
    "print(client.invoke(chain_of_thought_prompt).strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similary, there are other types of prompt engineering methods as well and some of them are:\n",
    "\n",
    "### 2.8 Role-Playing Prompt\n",
    "### 2.9 Scenario-Based Prompt\n",
    "### 2.10 Constraints Prompt\n",
    "\n",
    "and so on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03. Prompt Templates\n",
    "\n",
    "In LangChain, a __Prompt Template__ is a powerful tool used to create and manage reusable templates for prompts sent to large language models (LLMs). These templates help standardize and streamline the process of generating prompts for various tasks or queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import prompt template\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways to create **Prompt Template**\n",
    "\n",
    "- __`PromptTemplate()`__\n",
    "\n",
    "- __`PromptTemplate.from_template()`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a prompt template using `PromptTemplate()`\n",
    "prompt_temp_name = PromptTemplate(\n",
    "    input_variables=[\"planet\"],\n",
    "    template=\"How many moon does the planet {planet} have?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How many moon does the planet Jupiter have?'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the prompt template by assigning input_variable using `.format()`\n",
    "prompt1 = prompt_temp_name.format(planet=\"Jupiter\")\n",
    "prompt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How many moon does the planet Saturn have?'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt2 = prompt_temp_name.format(planet=\"Saturn\")\n",
    "prompt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a prompt template using `PromptTemplate.from_template()`\n",
    "prompt_temp_name1 = PromptTemplate.from_template(\"Who is the CEO of {company}?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Who is the CEO of Tesla?'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt3 = prompt_temp_name1.format(company=\"Tesla\")\n",
    "prompt3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Who is the CEO of Apple?'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt4 = prompt_temp_name1.format(company=\"Apple\")\n",
    "prompt4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 1: How many moon does the planet Jupiter have?\n",
      "Response: Jupiter has 79 known moons.\n",
      "\n",
      "------------------------------\n",
      "Prompt 2: How many moon does the planet Saturn have?\n",
      "Response: Saturn has 82 known moons.\n",
      "\n",
      "------------------------------\n",
      "Prompt 3: Who is the CEO of Tesla?\n",
      "Response: Elon Musk is the CEO of Tesla.\n",
      "\n",
      "------------------------------\n",
      "Prompt 4: Who is the CEO of Apple?\n",
      "Response: As of 2021, the CEO of Apple is Tim Cook.\n",
      "\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Generate the response of all prompts\n",
    "prompt_lists = [prompt1, prompt2, prompt3, prompt4]\n",
    "\n",
    "for idx, prompt in enumerate(prompt_lists):\n",
    "    print(f\"Prompt {idx+1}: {prompt}\")\n",
    "    print(f\"Response: {client.invoke(prompt).strip()}\")\n",
    "    print(\"---\" * 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04. Agents\n",
    "\n",
    "**Agents** are specialized components that handle specific tasks or interactions within a language model-based system. They can perform actions like \n",
    "- retrieving data or calling APIs, \n",
    "- manage complex queries, \n",
    "- facilitate communication between system components, and \n",
    "- maintain context throughout interactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Can you tell me who won the Copa America and Euro Cup recently?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt5 = \"Can you tell me who won the Copa America and Euro Cup recently?\"\n",
    "prompt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Copa America was won by Brazil in 2019, while the Euro Cup was won by Italy in 2021.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.invoke(prompt5).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In this notebook, created in **July 2024**, the response provided was **outdated**, referencing data from **2019** and **2021**. This is because the ChatGPT model is trained on past data, which results in it not being up-to-date.\n",
    "\n",
    "To extract **real-time information**, we use **SERP API** to call the **Google Search Engine** and extract information in real-time.\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "![SerpAPI](https://serpapi.com/assets/SerpApi-gentle-white-dc708ed0b09596cd08db74108b88af298123eeb384e872716b61d2a0ba1a1e03.png)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Getting Started with Serp API\n",
    "\n",
    "To get started with **SerpAPI**, follow these steps:\n",
    "\n",
    "1. **Create an Account**: Visit the [SerpAPI website](https://serpapi.com) and sign up for an account.\n",
    "\n",
    "2. **Get API Key**: Place the api key in `.env` under a variable name. \n",
    "\n",
    "3. **Install the Library**: In your terminal or command prompt, install the SerpAPI Python library by running the following command:\n",
    "\n",
    "   ```bash\n",
    "   pip install google-search-results\n",
    "   ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables form .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access environment variables \n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "serp_key = os.getenv(\"SERP_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary agent tools\n",
    "from langchain.agents import AgentType, load_tools\n",
    "from langchain.agents import create_react_agent\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "# Initiate LangChain OpenAI Client\n",
    "client = OpenAI()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize agent tool with SerpAPI and initialize OpenAI model\n",
    "tool = load_tools([\"serpapi\"], serpapi_api_key=serp_key)\n",
    "agent = initialize_agent(tools=tool, llm=client, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use a search engine to find this information\n",
      "Action: Search\n",
      "Action Input: \"Copa America and Euro Cup winners\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m['The CONMEBOL–UEFA Cup of Champions, previously known officially as the European/South American Nations Cup and also called Artemio Franchi Cup, ...', 'The Copa America 2024 and Euro 2024 have both reached their thrilling finals. In Europe, Spain emerged victorious, claiming the prestigious ...', '“There are some important teams that have advanced to the semi-finals of the Euros, teams that we faced in the World Cup, and it went well for ...', 'By Doug McIntyre: Argentina tops Colombia in extra time to win record-setting 16 Copa América win · By Laken Litman: Lionel Messi limps off in ...', \"Argentina have the most championships in the tournament's history, with 16 cups. The country that hosted the tournament the most times (nine editions) is ...\", \"Finals: Spain's 2-1 victory over England in the Euro Cup championship game on July 14, averaged 6.43 million viewers on Fox. The network says it ...\", \"CONMEBOL's Copa America and UEFA's EURO 2024 have offered lessons ahead of the 2026 World Cup, jointly hosted by the U.S., Mexico and ...\", \"It's why when you get to the quarter finals of your average world cup it tends to be Argentina, Brazil, and then a bunch of European teams.\", 'Euro 2020 winners Italy and Copa America champions Argentina will face each other in a friendly in June next summer — although a venue for the ...']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The winners of the Copa America and Euro Cup recently are Argentina and Spain, respectively.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Can you tell me who won the Copa America and Euro Cup recently?',\n",
       " 'output': 'The winners of the Copa America and Euro Cup recently are Argentina and Spain, respectively.'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's generate uptodate response with the help of SERPAPI agent\n",
    "agent.invoke(\"Can you tell me who won the Copa America and Euro Cup recently?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use a search engine to find this information.\n",
      "Action: Search\n",
      "Action Input: \"Kylian Mbappé recent transfer details\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mSources have told ESPN that Mbappé has signed a five-year deal worth €15 million ($16.2m) a year after taxes and will also receive a €150m signing on fee, spread over his deal. Madrid are the reigning LaLiga champions and lifted their 15th European Cup on Saturday as they beat Borussia Dortmund 2-0 at Wembley.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This information is from a reliable source, but I can double check with other sources to confirm.\n",
      "Action: Search\n",
      "Action Input: \"Kylian Mbappé transfer details\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mReal Madrid have announced the signing of Kylian Mbappe on a free transfer from Paris Saint-Germain with the France international joining the Spanish and European champions on a five-year deal once his contract expires in the French capital at the end of June.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This information seems to be consistent with the previous source.\n",
      "Action: Search\n",
      "Action Input: \"Real Madrid Kylian Mbappé transfer details\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mSources have told ESPN that Mbappé has signed a five-year deal worth €15 million ($16.2m) a year after taxes and will also receive a €150m signing on fee, spread over his deal. Madrid are the reigning LaLiga champions and lifted their 15th European Cup on Saturday as they beat Borussia Dortmund 2-0 at Wembley.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: Real Madrid has recently signed Kylian Mbappé on a five-year deal worth €15 million a year after taxes and a €150 million signing on fee.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '\\nWhich club has recently signed Kylian Mbappé, \\nand what are the details of the contracts, including the transfer fees?\\n',\n",
       " 'output': 'Real Madrid has recently signed Kylian Mbappé on a five-year deal worth €15 million a year after taxes and a €150 million signing on fee.'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's generate another response with current time period prompt \n",
    "agent.invoke(\"\"\"\n",
    "Which club has recently signed Kylian Mbappé, \n",
    "and what are the details of the contracts, including the transfer fees?\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract **real-time information**, we use can also use **Wikipedia** and extract information in real-time.\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "![Wikipedia](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQPGR14NEOF3Uhe_DWZh1ZiCEoiXIOt2DkzEw&s)\n",
    "</div>\n",
    "\n",
    "### 4.2 Getting Started with Wikipedia\n",
    "\n",
    "To get started with **Wikipedia**, follow these steps:\n",
    "\n",
    "**Install the Library**: In your terminal or command prompt, install the Wikipedia Python library by running the following command:\n",
    "\n",
    "   ```bash\n",
    "   pip install wikipedia\n",
    "   ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize agent tool with Wikipedia and initialize OpenAI model\n",
    "tool = load_tools([\"wikipedia\"], llm=client)\n",
    "agent = initialize_agent(tools=tool, llm=client, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should always think about what to do\n",
      "Action: wikipedia\n",
      "Action Input: Lionel Messi\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPage: Lionel Messi\n",
      "Summary: Lionel Andrés \"Leo\" Messi (Spanish pronunciation: [ljoˈnel anˈdɾes ˈmesi] ; born 24 June 1987) is an Argentine professional footballer who plays as a forward for and captains both Major League Soccer club Inter Miami and the Argentina national team. Widely regarded as one of the greatest players of all time, Messi has won a record eight Ballon d'Or awards, a record six European Golden Shoes, and was named the world's best player for a record eight times by FIFA. Messi is the most decorated player in the history of professional football, with 44 team trophies. Until 2021, he had spent his entire professional career with Barcelona, where he won a club-record 34 trophies, including ten La Liga titles, seven Copa del Rey titles, and the UEFA Champions League four times. With his country, he won two Copa América titles and the 2022 FIFA World Cup. A prolific goalscorer and creative playmaker, Messi holds the records for most goals (474), hat-tricks (36), and assists (192) in La Liga, most appearances (39) and assists (18) in the Copa América. He has the most international goals (109) and appearances (187) by a South American male. Messi has scored over 800 senior career goals for club and country, and the most goals for a single club (672).\n",
      "Messi relocated to Spain and joined Barcelona aged 13, making his competitive debut at age 17 in October 2004. He established himself as an integral player for the club within the next three years, and in his first uninterrupted season in 2008–09 helped Barcelona achieve the first treble in Spanish football; that year, aged 22, Messi won his first Ballon d'Or. Messi won four consecutive Ballons d'Or, the first player to win it four times. During the 2011–12 season, he set La Liga and European records for most goals in a season, while establishing himself as Barcelona's all-time top scorer. The following two seasons, he finished second for the Ballon d'Or behind Cristiano Ronaldo, his perceived career rival, before regaining his best form during the 2014–15 campaign, becoming the all-time top scorer in La Liga and leading Barcelona to a historic second treble, and was awarded a fifth Ballon d'Or in 2015. Messi assumed captaincy of Barcelona in 2018, and won a record sixth Ballon d'Or in 2019. He signed for French club Paris Saint-Germain in August 2021, spending two seasons there and winning Ligue 1 twice. Messi joined American club Inter Miami in July 2023, winning the Leagues Cup in August.\n",
      "An Argentine international, Messi is the country's all-time leading goalscorer and holds the national record for appearances. At youth level, he won the 2005 FIFA World Youth Championship and gold at the 2008 Summer Olympics. His style of play as a diminutive, left-footed dribbler drew comparisons with compatriot Diego Maradona, who described Messi as his successor. After his senior debut in 2005, Messi became the youngest Argentine to play and score in a FIFA World Cup (2006). As the squad's captain from 2011, he led Argentina to three consecutive finals: the 2014 FIFA World Cup, the 2015 Copa América and the 2016 Copa América. After announcing his international retirement in 2016, he returned to lead his country to qualification for the 2018 FIFA World Cup and victory in the 2021 Copa América. He led Argentina to win the 2022 World Cup, where he won a record second Golden Ball, scored seven goals including two in the final, and broke the record for most games played at the World Cup (26), later receiving his record-extending eighth Ballon d'Or in 2023. He then won a second Copa América as captain in 2024.\n",
      "Messi has endorsed sportswear company Adidas since 2006. According to France Football, he was the world's highest-paid footballer for five years out of six between 2009 and 2014, and was ranked the world's highest-paid athlete by Forbes in 2019 and 2022. Messi was among Time's 100 most influential people in the world in 2011, 2012, and 2023. In 2020 and 2023, he was named the L\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: Lionel Messi's journey to winning the 2022 World Cup included winning four Ballon d'Or awards, leading Barcelona to a historic second treble in the 2014-2015 season, and signing for French club Paris Saint-Germain in 2021 before joining American club Inter Miami in 2023. He also led Argentina to three consecutive finals, including victory in the 2021 Copa América and the 2022 World Cup, where he won a record second Golden Ball. Messi has also been named the world's highest-paid footballer and athlete multiple times and has been recognized as one of the most influential people in the world. \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"Can you tell me about Lionel Messi's journey to winning the 2022 World Cup?\",\n",
       " 'output': \"Lionel Messi's journey to winning the 2022 World Cup included winning four Ballon d'Or awards, leading Barcelona to a historic second treble in the 2014-2015 season, and signing for French club Paris Saint-Germain in 2021 before joining American club Inter Miami in 2023. He also led Argentina to three consecutive finals, including victory in the 2021 Copa América and the 2022 World Cup, where he won a record second Golden Ball. Messi has also been named the world's highest-paid footballer and athlete multiple times and has been recognized as one of the most influential people in the world.\"}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's generate updated response using wikipedia tool  \n",
    "agent.invoke(\"Can you tell me about Lionel Messi's journey to winning the 2022 World Cup?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should always think about what to do\n",
      "Action: wikipedia\n",
      "Action Input: Attention is All you Need\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPage: Attention Is All You Need\n",
      "Summary: \"Attention Is All You Need\" is a 2017 landmark research paper authored by eight scientists working at Google, that introduced a new deep learning architecture known as the transformer based on attention mechanisms proposed by Bahdanau et al. in 2014. It is considered by some to be a founding paper for modern artificial intelligence, as transformers became the main architecture of large language models like those based on GPT. At the time, the focus of the research was on improving Seq2seq techniques for machine translation, but even in their paper the authors saw the potential for other tasks like question answering and for what is now called multimodal Generative AI.\n",
      "The paper's title is a reference to the song \"All You Need Is Love\" by the Beatles.\n",
      "As of 2024, the paper has been cited more than 100,000 times.\n",
      "\n",
      "Page: All You Need Is Kill\n",
      "Summary: All You Need Is Kill is a Japanese science fiction light novel by Hiroshi Sakurazaka with illustrations by Yoshitoshi Abe. The book was published in Japanese by Shueisha under their Super Dash Bunko imprint in December 2004, and was later released in English by Viz Media under their Haikasoru imprint. All You Need Is Kill follows a soldier named Keiji Kiriya, who, after dying in a battle with extraterrestrials, is caught in a time loop that makes him live the same day repeatedly, allowing Kiriya to improve his fighting skills.\n",
      "A manga adaptation, written by Ryōsuke Takeuchi and illustrated by Takeshi Obata, was serialized in Shueisha's Weekly Young Jump magazine between January and May 2014 and was also published by Viz Media in its Weekly Shonen Jump magazine. In November 2014, the Viz translation was released in a collected edition that included the entire series. A separate graphic novel adaptation, written by Nick Mamatas and illustrated by Lee Ferguson, was released in North America in May 2014. A film adaptation from director Doug Liman starring Tom Cruise and Emily Blunt, titled Edge of Tomorrow, was released in May 2014. The English-language film tie-in edition of the novel also uses this title.\n",
      "The novel was Sakurazaka's breakthrough science fiction novel, earning wide praise from fellow novelists including Yasutaka Tsutsui and Chōhei Kanbayashi and was entered in contention for the Best Japanese Long Work in the 36th Seiun Awards in 2005.\n",
      "\n",
      "Page: All You Need Is Love\n",
      "Summary: \"All You Need Is Love\" is a song by the English rock band the Beatles that was released as a non-album single in July 1967, with \"Baby, You're a Rich Man\" as its B-side. It was written by John Lennon and credited to the Lennon–McCartney partnership. The song was Britain's contribution to Our World, the first live global television link, for which the band were filmed performing it at EMI Studios in London on 25 June. The programme was broadcast via satellite and seen by an audience of over 400 million in 25 countries. Lennon's lyrics were deliberately simplistic, to allow for the show's international audience, and captured the utopian ideals associated with the Summer of Love. The single topped sales charts in Britain, the United States and many other countries, and became an anthem for the counterculture's embrace of flower power philosophy.\n",
      "Our World coincided with the height of the Beatles' popularity and influence, following the release of their album Sgt. Pepper's Lonely Hearts Club Band. Rather than perform the song entirely live, the group played to a pre-recorded backing track. With an orchestral arrangement by George Martin, the song begins with a portion of the French national anthem and ends with musical quotations from works such as Glenn Miller's \"In the Mood\", \"Greensleeves\", Bach's Invention No. 8 in F major, and the Beatles' 1963 hit \"She Loves You\". Adding to the broadcast's festive atmosphere, the studio was adorned with signs and streamers and filled with guests dressed in psychedelic attire, including members of the Rolling Stones, the Who and\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: \"Attention is All You Need\" is a research paper that introduced a new deep learning architecture known as the transformer. It was published in 2017 and has been cited more than 100,000 times.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Let's generate another updated response using wikipedia tool for a prompt\n",
    "wikipedia_response = agent.invoke(\"Can you tell me about 'Attention is All you Need' research paper?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': \"Can you tell me about 'Attention is All you Need' research paper?\",\n",
       " 'output': '\"Attention is All You Need\" is a research paper that introduced a new deep learning architecture known as the transformer. It was published in 2017 and has been cited more than 100,000 times.'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikipedia_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Attention is All You Need\" is a research paper that introduced a new deep learning architecture known as the transformer. It was published in 2017 and has been cited more than 100,000 times.\n"
     ]
    }
   ],
   "source": [
    "print(wikipedia_response[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Agent Types Refrence Docs](https://api.python.langchain.com/en/latest/agents/langchain.agents.agent_types.AgentType.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
