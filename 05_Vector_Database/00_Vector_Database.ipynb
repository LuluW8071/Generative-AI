{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector\n",
    "\n",
    "A vector is like a list of numbers that represent something. Imagine you’re describing a point on a map using coordinates (like latitude and longitude). Similarly, a vector is a way to describe something with numbers.\n",
    "\n",
    "**Example:**\n",
    "If you have a picture of a cat, a vector could be used to represent this cat by listing numbers that describe various features of the picture.\n",
    "\n",
    "\n",
    "## Embeddings\n",
    "\n",
    "Embeddings are a special kind of vector that helps computers understand complex things, like words or images, in a way that makes them easier to work with. Think of embeddings as a way to turn something complex into a list of numbers that a computer can easily understand.\n",
    "\n",
    "**Example:**\n",
    "If you have the word \"apple,\" an embedding would turn it into a vector of numbers. This vector helps the computer understand the meaning of \"apple\" in relation to other words.\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "![Embeddings](https://miro.medium.com/v2/1*UCKRYEj85S3eH1uv1vFfCw.gif)\n",
    "<img src=\"https://cdn.sanity.io/images/vr8gru94/production/e016bbd4d7d57ff27e261adf1e254d2d3c609aac-2447x849.png\" width=\"700px\" height=\"300px\">\n",
    "</div>\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "| Embeddings without DL | Embeddings with DL | Others |\n",
    "| -------------- | ----------- | -- |\n",
    "|TF-IDF|Word2Vec| Glove (Matrix Factorization Based) |\n",
    "|N-Gram|FastText| |\n",
    "|Document Matrix(BoW)|ELMO| |\n",
    "|Integer Embeddings|BERT| |\n",
    "\n",
    "</div>\n",
    "\n",
    "### Rise of Embeddings with Deep Learning\n",
    "\n",
    "| **Aspect**               | **Old Embeddings (Without Deep Learning)**           | **New Embeddings (With Deep Learning)**             |\n",
    "|--------------------------|--------------------------------------------------------|------------------------------------------------------|\n",
    "| **Context**              | Use the same meaning for a word no matter where it appears. | Adjust the meaning of a word based on the surrounding words. |\n",
    "| **Meaning**              | Can struggle to show subtle differences in meaning.    | Better at capturing and showing subtle differences in meaning. |\n",
    "| **Multiple Meanings**    | Uses the same representation for words that have different meanings in different contexts. | Changes the representation of a word depending on its context. |\n",
    "| **Adaptability**         | Fixed and can’t easily adjust to new information or topics. | Can be updated and improved with new data or for specific topics. |\n",
    "| **Feature Learning**     | Needs a lot of manual work to figure out how to represent words. | Automatically learns and discovers useful features from large amounts of data. |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Vector Embeddings**\n",
    "\n",
    "**Vector embeddings** are numerical representations of data—like text, images, audio, or even users—converted into a **dense vector** (a list of floating-point numbers) that capture the meaning or features of the data in a machine-readable way.\n",
    "\n",
    "> Think of it as: *\"Turning raw data into points in a high-dimensional space where similar items are close together.\"*\n",
    "\n",
    "**Example (Text Embedding)**: Let’s say you use a model like OpenAI’s `text-embedding-ada-002` to embed:\n",
    "\n",
    "* \"cat\" → `[0.15, 0.8, -0.1, ...]` \n",
    "* \"dog\" → `[0.17, 0.79, -0.12, ...]`\n",
    "* \"airplane\" → `[0.92, -0.33, 0.88, ...]`\n",
    "\n",
    "Here, \"cat\" and \"dog\" will be close together in vector space, because they are semantically related, but \"airplane\" will be far away.\n",
    "\n",
    "\n",
    "## **Vector Database**\n",
    "\n",
    "A **vector database** is a special type of database designed to **store, index, and search vector embeddings efficiently**, especially in high-dimensional spaces.\n",
    "\n",
    "Unlike traditional databases that search with exact matches or filters, vector DBs perform **similarity search**. They power **semantic search**, recommendation systems, and generative AI memory.\n",
    "\n",
    "### Key Functions:\n",
    "\n",
    "* Store millions (or billions) of embeddings\n",
    "\n",
    "* Perform **Approximate Nearest Neighbor (ANN)** search (e.g. find 10 closest vectors to a given vector)\n",
    "* Support metadata filters (e.g. only search among items tagged \"Nepali articles\")\n",
    "\n",
    "**Examples**: Pinecone, FAISS, PineCone, ChromaDB, Weaviate\n",
    "\n",
    "### Use Cases:\n",
    "\n",
    "* **Semantic search**: Search for \"Who built the Taj Mahal?\" → it retrieves documents that don’t contain exact words but related content.\n",
    "\n",
    "* **Similarity search**: \"Search similar images, text, audio, ...\"\n",
    "* **Chatbot memory**: Store previous conversations as vectors, retrieve relevant ones when user asks something related.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
