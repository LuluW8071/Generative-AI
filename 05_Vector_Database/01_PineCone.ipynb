{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8fc3f7e5",
      "metadata": {
        "id": "8fc3f7e5"
      },
      "source": [
        "<center>\n",
        "\n",
        "<img src=\"https://kajabi-storefronts-production.kajabi-cdn.com/kajabi-storefronts-production/file-uploads/sites/2148158644/images/85d1d5-f44-11de-03a0-b8b70657ae6f_pinecone.jpeg\" width=80%>\n",
        "</center>\n",
        "\n",
        "**[Pinecone](https://www.pinecone.io/)** is a fully managed vector database built specifically for **high-performance vector search**. It helps you **store, index, and search vector embeddings** at scale without managing the infrastructure yourself."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2834e06",
      "metadata": {
        "id": "a2834e06"
      },
      "source": [
        "To use **Pinecone** for semantic vector storage and search, we’ll need:\n",
        "\n",
        "* `langchain`: for chaining and embedding integration  \n",
        "* `pinecone-client`: to interact with **Pinecone DB**  \n",
        "* Either:\n",
        "  * `openai` + `tiktoken`: for **OpenAI embeddings**  \n",
        "  * `google-generativeai`: for **Gemini embeddings**  \n",
        "\n",
        "**Steps:**\n",
        "\n",
        "1. **Get API Keys**\n",
        "\n",
        "   * Create an account on Pinecone and obtain your Pinecone API key.\n",
        "   * Obtain an API key from either OpenAI or Google, depending on whether you want to use OpenAI embeddings or Gemini embeddings.\n",
        "\n",
        "2. **Initialize Pinecone**\n",
        "\n",
        "   Connect your application to Pinecone using the API key and select or create an index where your vectors will be stored.\n",
        "\n",
        "3. **Generate Embeddings**\n",
        "\n",
        "   Use an embedding model (from OpenAI or Gemini) to convert text into numerical vector representations.\n",
        "\n",
        "4. **Ingest Vectors**\n",
        "\n",
        "   Store these generated vectors in Pinecone’s index, optionally attaching metadata such as the original text or tags.\n",
        "\n",
        "5. **Search Embed Query**\n",
        "\n",
        "   Convert a new query into an embedding and search Pinecone to retrieve the most similar vectors, along with their metadata, in real-time.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb8ee023",
      "metadata": {
        "id": "bb8ee023",
        "outputId": "9bafe3f4-8130-4ec5-ebce-dec82261ac99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m2.1/2.5 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.5/323.5 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Install necessary libraries (using gemini embeddings)\n",
        "!pip install langchain langchain-community pinecone-client pypdf -q\n",
        "!pip install \"google-ai-generativelanguage>=0.6.18,<0.7.0\" langchain-google-genai -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "431665a1",
      "metadata": {
        "id": "431665a1"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e97c4b89",
      "metadata": {
        "id": "e97c4b89"
      },
      "outputs": [],
      "source": [
        "loader = PyPDFLoader(\"MachineTranslationwithAttention.pdf\")\n",
        "pages = []\n",
        "async for page in loader.alazy_load():\n",
        "    pages.append(page)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a9648ce",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a9648ce",
        "outputId": "c9084e37-aa59-4fd1-97c4-571f73cb1804"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'producer': 'pdfTeX-1.40.21',\n",
              " 'creator': 'LaTeX with hyperref',\n",
              " 'creationdate': '2021-11-05T20:59:50+00:00',\n",
              " 'author': '',\n",
              " 'keywords': '',\n",
              " 'moddate': '2021-11-05T20:59:50+00:00',\n",
              " 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
              " 'subject': '',\n",
              " 'title': '',\n",
              " 'trapped': '/False',\n",
              " 'rgid': 'PB:355917108_AS:1086893412356097@1636146991241',\n",
              " 'source': 'MachineTranslationwithAttention.pdf',\n",
              " 'total_pages': 11,\n",
              " 'page': 0,\n",
              " 'page_label': '1'}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "pages[0].metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91af779d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "91af779d",
        "outputId": "cf3341ff-347a-4404-9b79-bfb06a4c446a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Neural Machine Translation with Attention\\nMohammad Wasil Saleem\\nMatrikel-Nr.: 805779\\nUniversit¨at Potsdam\\nsaleem1@uni-potsdam.de\\nSandeep Uprety\\nMatrikel-Nr. 804982\\nUniversit¨at Potsdam\\nuprety@uni-potsdam.de\\nAbstract\\nIn recent years, the success achieved\\nthrough neural machine translation has\\nmade it mainstream in machine translation\\nsystems. In this work, encoder-decoder\\nwith attention system based on ”Neural\\nMachine Translation by Jointly Learning\\nto Align and Translate” by Bahdanau et al.\\n(2014) has been used to accomplish the\\nMachine Translation between English and\\nSpanish Language which has not seen\\nmuch research work done as compared\\nto other languages such as German and\\nFrench. We aim to demonstrate the re-\\nsults similar to the breakthrough paper on\\nwhich our work is based on. We achieved\\na BLEU score of 25.37, which was close\\nenough to what Bahdanau et al. (2014)\\nachieved in their work.\\n1 Introduction\\nMachine Translation (MT) is the task of translat-\\ning text without human assistance while preserv-\\ning the meaning of input text. The early approach\\nto machine translation relied heavily on hand-\\ncrafted translation rules and linguistic knowledge.\\nStarted in early around 1950s, unlike rule-based\\nmachine translation, Statistical machine transla-\\ntion (SMT) generated translations based on statis-\\ntical models whose parameters are derived from\\nthe analysis of bilingual text corpora (Koehn et al.,\\n2003). Though reliable, for SMT, it can be hard\\nto ﬁnd content for obscure languages and is less\\nsuitable for language pairs with big differences\\nin word order making the quality of translation\\nfar from satisfactory. With the progress in deep\\nlearning being applied to MT, in 2014, end-to-end\\nneural network translation model was proposed\\nby (Bahdanau et al., 2014; Sutskever et al., 2014)\\nwhere the term ”neural machine translation” was\\nformally used. Neural machine translation (NMT)\\nis the newest method of MT that uses a single\\nlarge neural network to model the entire transla-\\ntion process, freeing the need for excessive fea-\\nture engineering. Through the rapid research and\\nbreakthroughs, end-to-end neural machine trans-\\nlation has gained remarkable performances (Shi\\net al., 2021; Bahdanau et al., 2014) and have be-\\ncome mainstream approach to MT.\\n2 Related Work\\nEarly problem of NMT was often the poor trans-\\nlation for long sentences (Sutskever et al., 2014)\\nwhich can be attributed to the ﬁxed-length of\\nsource encoding in conventional encoder-decoder\\nas suggested by Cho et al. (2014a) for which the\\nconcept of attention to NMT was introduced by\\nBahdanau et al. (2014) to avoid keeping a ﬁxed\\nsource side representation.\\nAs compared to separately tuned components in\\nSMT, newly emerging Neural Machine translation\\nradically departures from previous machine learn-\\ning approaches as the training of NMT is end-to-\\nend which has signiﬁcantly improved translation\\nquality across 30 different languages (Junczys-\\nDowmunt et al., 2016). NMT model can be attrac-\\ntive for various reason one being scalability issue,\\nwhether it be memory requirements or computa-\\ntional speed. Another being able to train all the\\ncharacter embedding as each characters frequently\\noccurs in the training corpus.\\nMost neural machine translation models pro-\\nposed use encoder-decoder where a neural net-\\nwork reads and encodes a source sentence into\\na ﬁxed-length vector and a decoder then outputs\\na translation from the encoded vector, where in\\nmost of the cases the encoder and decoder are\\nmainly implemented as RNNs, CNNs or self-\\nattention network (Wu et al., 2018). The whole\\nencoder–decoder system, which consists of the\\nencoder and the decoder for a language pair, is'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "pages[1].page_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad257296",
      "metadata": {
        "id": "ad257296"
      },
      "outputs": [],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1024,\n",
        "    chunk_overlap=32\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92eff667",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92eff667",
        "outputId": "d003bd26-2312-4686-bb7d-b05039b733e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-11-05T20:59:50+00:00', 'author': '', 'keywords': '', 'moddate': '2021-11-05T20:59:50+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'rgid': 'PB:355917108_AS:1086893412356097@1636146991241', 'source': 'MachineTranslationwithAttention.pdf', 'total_pages': 11, 'page': 0, 'page_label': '1'}, page_content='See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/355917108\\nNeural Machine Translation with Attention\\nTechnical Report · August 2021\\nDOI: 10.13140/RG.2.2.29381.37607/1\\nCITATION\\n1\\nREADS\\n5,448\\n2 authors:\\nMohammad Wasil Saleem\\nUniversität Potsdam\\n4 PUBLICATIONS\\xa0\\xa0\\xa02 CITATIONS\\xa0\\xa0\\xa0\\nSEE PROFILE\\nSandeep Uprety\\nUniversität Potsdam\\n1 PUBLICATION\\xa0\\xa0\\xa01 CITATION\\xa0\\xa0\\xa0\\nSEE PROFILE\\nAll content following this page was uploaded by Sandeep Uprety on 05 November 2021.\\nThe user has requested enhancement of the downloaded file.'),\n",
              " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-11-05T20:59:50+00:00', 'author': '', 'keywords': '', 'moddate': '2021-11-05T20:59:50+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'rgid': 'PB:355917108_AS:1086893412356097@1636146991241', 'source': 'MachineTranslationwithAttention.pdf', 'total_pages': 11, 'page': 1, 'page_label': '2'}, page_content='Neural Machine Translation with Attention\\nMohammad Wasil Saleem\\nMatrikel-Nr.: 805779\\nUniversit¨at Potsdam\\nsaleem1@uni-potsdam.de\\nSandeep Uprety\\nMatrikel-Nr. 804982\\nUniversit¨at Potsdam\\nuprety@uni-potsdam.de\\nAbstract\\nIn recent years, the success achieved\\nthrough neural machine translation has\\nmade it mainstream in machine translation\\nsystems. In this work, encoder-decoder\\nwith attention system based on ”Neural\\nMachine Translation by Jointly Learning\\nto Align and Translate” by Bahdanau et al.\\n(2014) has been used to accomplish the\\nMachine Translation between English and\\nSpanish Language which has not seen\\nmuch research work done as compared\\nto other languages such as German and\\nFrench. We aim to demonstrate the re-\\nsults similar to the breakthrough paper on\\nwhich our work is based on. We achieved\\na BLEU score of 25.37, which was close\\nenough to what Bahdanau et al. (2014)\\nachieved in their work.\\n1 Introduction\\nMachine Translation (MT) is the task of translat-\\ning text without human assistance while preserv-'),\n",
              " Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2021-11-05T20:59:50+00:00', 'author': '', 'keywords': '', 'moddate': '2021-11-05T20:59:50+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'rgid': 'PB:355917108_AS:1086893412356097@1636146991241', 'source': 'MachineTranslationwithAttention.pdf', 'total_pages': 11, 'page': 1, 'page_label': '2'}, page_content='ing the meaning of input text. The early approach\\nto machine translation relied heavily on hand-\\ncrafted translation rules and linguistic knowledge.\\nStarted in early around 1950s, unlike rule-based\\nmachine translation, Statistical machine transla-\\ntion (SMT) generated translations based on statis-\\ntical models whose parameters are derived from\\nthe analysis of bilingual text corpora (Koehn et al.,\\n2003). Though reliable, for SMT, it can be hard\\nto ﬁnd content for obscure languages and is less\\nsuitable for language pairs with big differences\\nin word order making the quality of translation\\nfar from satisfactory. With the progress in deep\\nlearning being applied to MT, in 2014, end-to-end\\nneural network translation model was proposed\\nby (Bahdanau et al., 2014; Sutskever et al., 2014)\\nwhere the term ”neural machine translation” was\\nformally used. Neural machine translation (NMT)\\nis the newest method of MT that uses a single\\nlarge neural network to model the entire transla-')]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "text_chunks = text_splitter.split_documents(pages)\n",
        "text_chunks[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a6b1335",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9a6b1335",
        "outputId": "081fa109-8249-42bb-9ae9-3ba9dadd3296"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tion process, freeing the need for excessive fea-\n",
            "ture engineering. Through the rapid research and\n",
            "breakthroughs, end-to-end neural machine trans-\n",
            "lation has gained remarkable performances (Shi\n",
            "et al., 2021; Bahdanau et al., 2014) and have be-\n",
            "come mainstream approach to MT.\n",
            "2 Related Work\n",
            "Early problem of NMT was often the poor trans-\n",
            "lation for long sentences (Sutskever et al., 2014)\n",
            "which can be attributed to the ﬁxed-length of\n",
            "source encoding in conventional encoder-decoder\n",
            "as suggested by Cho et al. (2014a) for which the\n",
            "concept of attention to NMT was introduced by\n",
            "Bahdanau et al. (2014) to avoid keeping a ﬁxed\n",
            "source side representation.\n",
            "As compared to separately tuned components in\n",
            "SMT, newly emerging Neural Machine translation\n",
            "radically departures from previous machine learn-\n",
            "ing approaches as the training of NMT is end-to-\n",
            "end which has signiﬁcantly improved translation\n",
            "quality across 30 different languages (Junczys-\n",
            "Dowmunt et al., 2016). NMT model can be attrac-\n"
          ]
        }
      ],
      "source": [
        "print(text_chunks[3].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b215e97",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b215e97",
        "outputId": "d2287db9-5b90-4e63-a8a3-e51fcf869643"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tive for various reason one being scalability issue,\n",
            "whether it be memory requirements or computa-\n",
            "tional speed. Another being able to train all the\n",
            "character embedding as each characters frequently\n",
            "occurs in the training corpus.\n",
            "Most neural machine translation models pro-\n",
            "posed use encoder-decoder where a neural net-\n",
            "work reads and encodes a source sentence into\n",
            "a ﬁxed-length vector and a decoder then outputs\n",
            "a translation from the encoded vector, where in\n",
            "most of the cases the encoder and decoder are\n",
            "mainly implemented as RNNs, CNNs or self-\n",
            "attention network (Wu et al., 2018). The whole\n",
            "encoder–decoder system, which consists of the\n",
            "encoder and the decoder for a language pair, is\n"
          ]
        }
      ],
      "source": [
        "print(text_chunks[4].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15e2f44e",
      "metadata": {
        "id": "15e2f44e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load the .env file\n",
        "load_dotenv()\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
        "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
        "PINECONE_API_ENV = \"GenAI\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
        "\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"text-embedding-004\")\n",
        "vector = embeddings.embed_query(\"hello, world!\")\n",
        "vector[:5]"
      ],
      "metadata": {
        "id": "a1odS5_RBT9X",
        "outputId": "ae3562d4-0709-4980-98b1-082cd0a6ff26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "a1odS5_RBT9X",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.006846265867352486,\n",
              " -0.02251487784087658,\n",
              " -0.05496913567185402,\n",
              " -0.020021894946694374,\n",
              " -0.010026923380792141]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a248576c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a248576c",
        "outputId": "d3396d48-4e97-48d9-d68d-fba56ee03f0d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "len(vector)     # Dimension of the embedding model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f310716",
      "metadata": {
        "id": "4f310716"
      },
      "source": [
        "Now let's install `langchain-pinecone`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-pinecone -q"
      ],
      "metadata": {
        "id": "zYZy5TF7BmTy",
        "outputId": "1d5712ec-c9fa-4df1-a630-5d346af4a8b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "zYZy5TF7BmTy",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/75.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/449.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m449.5/449.5 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.6/587.6 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.3/259.3 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Creating an Index in Pinecone\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "1. Let’s start by going to the **Pinecone dashboard** and logging in to your account.\n",
        "2. From the top navigation bar, let’s click on **Database**.\n",
        "3. Next, let’s click **Create Index**.\n",
        "4. Let’s enter a name for the new index (pick any name you prefer).\n",
        "\n",
        "### Configuration\n",
        "\n",
        "* **Vector type**: `Dense`\n",
        "* **Dimensions**: `768`\n",
        "* **Metric**: `cosine`\n",
        "\n",
        "Let’s leave the other cloud options as they are by default.\n",
        "\n",
        "5. Finally, let’s click **Create** to finish.\n"
      ],
      "metadata": {
        "id": "BNdevn9lClc0"
      },
      "id": "BNdevn9lClc0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbd7a4ff",
      "metadata": {
        "id": "fbd7a4ff",
        "outputId": "ebc475c6-0e83-411d-da4c-8c57ba23b5f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/langchain_pinecone/__init__.py:3: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
            "\n",
            "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
            "with: `from pydantic import BaseModel`\n",
            "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
            "\n",
            "  from langchain_pinecone.vectorstores import Pinecone, PineconeVectorStore\n"
          ]
        }
      ],
      "source": [
        "from langchain_pinecone.vectorstores import Pinecone as PC\n",
        "from pinecone import Pinecone\n",
        "\n",
        "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
        "\n",
        "index_name = \"generative-ai\"\n",
        "index = pc.Index(index_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8991c7de",
      "metadata": {
        "id": "8991c7de"
      },
      "source": [
        "### Create Embeddings for each of the Text Chunk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75c9bcc7",
      "metadata": {
        "id": "75c9bcc7"
      },
      "outputs": [],
      "source": [
        "# PineCone Vector DB Search\n",
        "docsearch = PC.from_texts(\n",
        "    [t.page_content for t in text_chunks],\n",
        "    embedding=embeddings,\n",
        "    index_name=index_name\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d89a1c77",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d89a1c77",
        "outputId": "28c1455f-4af5-4417-db86-0570ae1077c4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain_pinecone.vectorstores.Pinecone at 0x7c89e871ede0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "docsearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4e4acb2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4e4acb2",
        "outputId": "356b4594-4da3-4afc-b334-7ad28a38339c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='e9433bd9-6bc5-4005-a2e3-4ceac887450a', metadata={}, page_content='to memorize the words coming at the beginning\\nof the sentences, which leads to poor translation\\nof the source sentence. The Attention mechanism\\njust addresses this issue, by retaining and utilising\\nall the hidden state of the input sentence during the\\ndecoding phase.\\nDuring the decoding phase, the model creates\\nan alignment between each time step of the de-\\ncoder output and all of the encoder hidden state.\\nWe need to learn this alignment. Each output of\\nthe decoder can selectively pick out speciﬁc ele-\\nments from the sequence to produce the output.\\nSo, this allows the model to focus and pay more\\n”Attention” to the relevant part of the input se-\\nquence.\\nThe ﬁrst attention model was proposed by Bah-\\ndanau et al. (2014), there are several other types of\\nattention proposed, such as the one by Luong et al.'),\n",
              " Document(id='cfe30c6b-e827-4bd2-8a7c-e9df3b595c10', metadata={}, page_content='to memorize the words coming at the beginning\\nof the sentences, which leads to poor translation\\nof the source sentence. The Attention mechanism\\njust addresses this issue, by retaining and utilising\\nall the hidden state of the input sentence during the\\ndecoding phase.\\nDuring the decoding phase, the model creates\\nan alignment between each time step of the de-\\ncoder output and all of the encoder hidden state.\\nWe need to learn this alignment. Each output of\\nthe decoder can selectively pick out speciﬁc ele-\\nments from the sequence to produce the output.\\nSo, this allows the model to focus and pay more\\n”Attention” to the relevant part of the input se-\\nquence.\\nThe ﬁrst attention model was proposed by Bah-\\ndanau et al. (2014), there are several other types of\\nattention proposed, such as the one by Luong et al.'),\n",
              " Document(id='40a8193d-d9a5-4c6d-84f7-9be8e831e183', metadata={}, page_content='tends to remember the words that occured very\\nearly in the sequence, it will still not be able to\\nlearn the alignment between the source word and\\nthe target word. They often forget the initial part\\nof the sentence once they are processed in the en-\\ncoder. That is why we use an alignment mecha-\\nnism called attention. They help to memorize this\\ninformation for longer sentences. But we need to\\nlearn this alignment. It can vary from language to\\nlanguage.\\n3.2 Attention\\nIn this section, we will speciﬁcally deﬁne the\\nalignment mechanism, [See Figure 2] that we used\\nin our model. In RNN Encoder-Decoder model\\n(Sutskever et al., 2014), we faced with the bottle-\\nneck problem, where the complete sequence of in-\\nformation of the source sentence, must be captured\\nby one single vector, i.e. the last hidden unit of the\\nencoder RNN is used as a context vector for the\\ndecoder, which becomes difﬁcult for the decoder\\nto summarise large input sequence at once. This\\nalso poses a problem where the encoder is not able'),\n",
              " Document(id='1a28305e-d765-471b-8284-8c24efb139f3', metadata={}, page_content='tends to remember the words that occured very\\nearly in the sequence, it will still not be able to\\nlearn the alignment between the source word and\\nthe target word. They often forget the initial part\\nof the sentence once they are processed in the en-\\ncoder. That is why we use an alignment mecha-\\nnism called attention. They help to memorize this\\ninformation for longer sentences. But we need to\\nlearn this alignment. It can vary from language to\\nlanguage.\\n3.2 Attention\\nIn this section, we will speciﬁcally deﬁne the\\nalignment mechanism, [See Figure 2] that we used\\nin our model. In RNN Encoder-Decoder model\\n(Sutskever et al., 2014), we faced with the bottle-\\nneck problem, where the complete sequence of in-\\nformation of the source sentence, must be captured\\nby one single vector, i.e. the last hidden unit of the\\nencoder RNN is used as a context vector for the\\ndecoder, which becomes difﬁcult for the decoder\\nto summarise large input sequence at once. This\\nalso poses a problem where the encoder is not able')]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "query=\"What is Attention Mechanism?\"\n",
        "\n",
        "docs = docsearch.similarity_search(query)  # Top-k search\n",
        "docs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(docs[0].page_content)"
      ],
      "metadata": {
        "id": "vnEawnF0TNsc",
        "outputId": "8be8df6a-88c0-48be-9199-55d33f93c484",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "vnEawnF0TNsc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "to memorize the words coming at the beginning\n",
            "of the sentences, which leads to poor translation\n",
            "of the source sentence. The Attention mechanism\n",
            "just addresses this issue, by retaining and utilising\n",
            "all the hidden state of the input sentence during the\n",
            "decoding phase.\n",
            "During the decoding phase, the model creates\n",
            "an alignment between each time step of the de-\n",
            "coder output and all of the encoder hidden state.\n",
            "We need to learn this alignment. Each output of\n",
            "the decoder can selectively pick out speciﬁc ele-\n",
            "ments from the sequence to produce the output.\n",
            "So, this allows the model to focus and pay more\n",
            "”Attention” to the relevant part of the input se-\n",
            "quence.\n",
            "The ﬁrst attention model was proposed by Bah-\n",
            "danau et al. (2014), there are several other types of\n",
            "attention proposed, such as the one by Luong et al.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23b30306",
      "metadata": {
        "id": "23b30306"
      },
      "outputs": [],
      "source": [
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dry run without context\n",
        "result = llm.invoke(\"What is attention mechanism in short description?\")\n",
        "print(result.content)"
      ],
      "metadata": {
        "id": "JyML6_15MxBQ",
        "outputId": "406e2d36-989e-473a-86e2-428afec49ca4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "JyML6_15MxBQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The attention mechanism allows a neural network to focus on the most relevant parts of the input data when making predictions, rather than treating all parts equally. It essentially assigns weights to different parts of the input, highlighting the important information and suppressing the irrelevant noise.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30f1a358",
      "metadata": {
        "id": "30f1a358"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# Setting up a system prompt\n",
        "system_prompt = (\n",
        "    \"Use the given context to answer the question. \"\n",
        "    \"If you don't know the answer, say you don't know. \"\n",
        "    \"Use three sentence maximum and keep the answer concise. \"\n",
        "    \"Context: {context}\"\n",
        ")\n",
        "\n",
        "# Chat Prompt Template\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_prompt),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "retriever = docsearch.as_retriever()\n",
        "\n",
        "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
        "chain = create_retrieval_chain(retriever, question_answer_chain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a4e1637",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a4e1637",
        "outputId": "423993d1-5ce2-4183-9e29-f4fb14f5d579"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input': 'What is attention mechanism in short description?', 'context': [Document(id='cfe30c6b-e827-4bd2-8a7c-e9df3b595c10', metadata={}, page_content='to memorize the words coming at the beginning\\nof the sentences, which leads to poor translation\\nof the source sentence. The Attention mechanism\\njust addresses this issue, by retaining and utilising\\nall the hidden state of the input sentence during the\\ndecoding phase.\\nDuring the decoding phase, the model creates\\nan alignment between each time step of the de-\\ncoder output and all of the encoder hidden state.\\nWe need to learn this alignment. Each output of\\nthe decoder can selectively pick out speciﬁc ele-\\nments from the sequence to produce the output.\\nSo, this allows the model to focus and pay more\\n”Attention” to the relevant part of the input se-\\nquence.\\nThe ﬁrst attention model was proposed by Bah-\\ndanau et al. (2014), there are several other types of\\nattention proposed, such as the one by Luong et al.'), Document(id='40a8193d-d9a5-4c6d-84f7-9be8e831e183', metadata={}, page_content='tends to remember the words that occured very\\nearly in the sequence, it will still not be able to\\nlearn the alignment between the source word and\\nthe target word. They often forget the initial part\\nof the sentence once they are processed in the en-\\ncoder. That is why we use an alignment mecha-\\nnism called attention. They help to memorize this\\ninformation for longer sentences. But we need to\\nlearn this alignment. It can vary from language to\\nlanguage.\\n3.2 Attention\\nIn this section, we will speciﬁcally deﬁne the\\nalignment mechanism, [See Figure 2] that we used\\nin our model. In RNN Encoder-Decoder model\\n(Sutskever et al., 2014), we faced with the bottle-\\nneck problem, where the complete sequence of in-\\nformation of the source sentence, must be captured\\nby one single vector, i.e. the last hidden unit of the\\nencoder RNN is used as a context vector for the\\ndecoder, which becomes difﬁcult for the decoder\\nto summarise large input sequence at once. This\\nalso poses a problem where the encoder is not able'), Document(id='f6daeb96-8c6c-49ee-b676-58aa7c32b1a4', metadata={}, page_content='Figure 2: Attention Model (Luong et al., 2015)\\nuse the information from the past, present as well\\nas from the future. We need the entire sequence of\\ndata before we can make any predictions.\\nThe architecture that we are proposing here is\\nbased on the Encoder-Decoder Framework. The\\nencoder takes in the input sentence and converts\\nthem into a vector representation\\nThe encoder can be an RNN (Cho et al., 2014b)\\nor LSTM unit (Sutskever et al., 2014). They pro-\\ncesses the input sentence, pass it through RNN or\\nLSTM, and when it encounters the end of sen-\\ntence, then the hidden state, that captured all the\\nrelevant information passes it to the decoder. Then\\nthis information is used to predict the translations\\nin the decoder, which can be RNN or LSTM, until\\nit predicts the end of the sentence token. The hid-\\nden state needs to remember every word from the\\ninput sentence. So that is why this model tends to\\nwork for short sentences and not long sentences.\\nEven though if we used LSTM or GRU, which'), Document(id='1ead1d06-ff0e-4eda-9efe-bfc63d612af6', metadata={}, page_content='Table 1: Examples of Spanish and English sentences from the dataset\\n(2015).\\nWe will only discuss the attention model, pro-\\nposed by Bahdanau et al. (2014). After the in-\\nput sequence is passed through the encoder, it pro-\\nduces hidden state for each of the elements in the\\nsequence (h1,...,h Tx ). Then we multiply the de-\\ncoders hidden state at time step t (s1,...,s Ty ),\\nwith all of the encoders hidden state, which gives\\nus the alignment score of each of the encoder out-\\nput with respect to the decoder input and hidden\\nstate at that time step:\\net = [sT\\nt h1,...,s T\\nt hTx ]\\nThe alignment score quantiﬁes the amount of\\nAttention the decoder will place on each of the en-\\ncoder outputs when producing the next output, so\\ninstead of looking at the entire sequence, it just\\nconcentrate on few relevant parts of the sequence\\nwhen predicting the next word.\\nAfter calculating the alignment score, we pass\\nthe vector et through the softmax layer, to calcu-\\nlate the probability distribution.\\nαt = softmax(et)')], 'answer': 'The Attention mechanism addresses the issue of forgetting initial parts of sentences by retaining and utilizing all hidden states of the input sentence during decoding. It creates an alignment between each decoder output time step and all encoder hidden states. This allows the model to focus on relevant parts of the input sequence, improving translation.'}\n"
          ]
        }
      ],
      "source": [
        "query=\"What is attention mechanism in short description?\"\n",
        "result = chain.invoke({\"input\": query})\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result[\"answer\"])"
      ],
      "metadata": {
        "id": "mLVw5ZI1OLF6",
        "outputId": "fe67c32d-78af-4ea5-f8e4-ce94b6968933",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "mLVw5ZI1OLF6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Attention mechanism addresses the issue of forgetting initial parts of sentences by retaining and utilizing all hidden states of the input sentence during decoding. It creates an alignment between each decoder output time step and all encoder hidden states. This allows the model to focus on relevant parts of the input sequence, improving translation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd4c9df2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "dd4c9df2",
        "outputId": "3d384231-2468-4a87-a4c5-63f728c284da"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The attention mechanism improves translation by retaining and utilizing all hidden states of the input sentence during decoding, allowing the model to focus on relevant parts of the input sequence. Bahdanau et al. (2014) achieved a BLEU score of 26.75 using the attention mechanism, while Cho et al. (2014b) reported a BLEU score of 17.82 without it. The attention mechanism addresses the issue of memorizing words at the beginning of sentences, which can lead to poor translation.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "new_query = \"\"\"\n",
        "\"How can attention mechanism improve the translation task?\n",
        "What BLEU score was reported when using and not using the attention mechanism\n",
        "\"\"\"\n",
        "\n",
        "response = chain.invoke({\"input\": new_query})\n",
        "response[\"answer\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cc78202",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cc78202",
        "outputId": "63e333d0-f248-41e9-dda4-0e2737a2d4bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(id='0a04ce7a-c286-460e-a666-10d168c7d725', metadata={}, page_content='proach by Bahdanau et al. (2014), where the per-\\nformance of the encoder-decoder with attention\\nshows no deterioration with sentence of length\\ngreater than 50 sentences. The result that we\\ngot which was 25.76 was quite close to the Bah-\\ndanau et al. (2014), where they got BLEU score of\\n26.75,training with 1000 encoder and decoder di-\\nmensions, and training on corpus of 384M words.\\nThey were also able to achieve BLEU score of\\n28.45 when trained the data until the performance\\nof the validation stopped improving.\\n6.2 Qualitative Results\\nThe model proposed by Bahdanau et al. (2014)\\nprovides a way to investigate the soft alignment\\nbetween the translated sentence from the model\\nand the input sentence. The matrix given in Fig\\n3, each of the cells represent the weights αij of\\nthe annotation of the j-th source word for the i-\\nth target word. This helps in visualizing and see\\nwhich word from the input sentence were con-\\nsidered more important for generating the target\\nword.\\nWe see that majority of the weights are con-')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# Lets check its context\n",
        "response[\"context\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response[\"context\"][1]"
      ],
      "metadata": {
        "id": "jgQLygR1P-t_",
        "outputId": "0c98d086-f9a8-4e8d-f461-511c27cb8c76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "jgQLygR1P-t_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(id='cfe30c6b-e827-4bd2-8a7c-e9df3b595c10', metadata={}, page_content='to memorize the words coming at the beginning\\nof the sentences, which leads to poor translation\\nof the source sentence. The Attention mechanism\\njust addresses this issue, by retaining and utilising\\nall the hidden state of the input sentence during the\\ndecoding phase.\\nDuring the decoding phase, the model creates\\nan alignment between each time step of the de-\\ncoder output and all of the encoder hidden state.\\nWe need to learn this alignment. Each output of\\nthe decoder can selectively pick out speciﬁc ele-\\nments from the sequence to produce the output.\\nSo, this allows the model to focus and pay more\\n”Attention” to the relevant part of the input se-\\nquence.\\nThe ﬁrst attention model was proposed by Bah-\\ndanau et al. (2014), there are several other types of\\nattention proposed, such as the one by Luong et al.')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> You can create a basic chatbot functionality by running the code cell block below"
      ],
      "metadata": {
        "id": "62O9_oQkNa8G"
      },
      "id": "62O9_oQkNa8G"
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "while True:\n",
        "  user_input = input(f\"Input Prompt:\\n\\t\")\n",
        "  if user_input == \"exit\":\n",
        "    print(\"Exiting!!!\")\n",
        "    sys.exit()\n",
        "  if user_input == \"\":\n",
        "    continue\n",
        "  response = chain.invoke({\"input\": user_input})\n",
        "  print(f\"Response:\\n\\t{response[\"answer\"]}\\n\")"
      ],
      "metadata": {
        "id": "hgTgcKi4Q77V"
      },
      "id": "hgTgcKi4Q77V",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}