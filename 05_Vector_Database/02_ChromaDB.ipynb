{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNLh9gpC9BsPta8MllO5YR+"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b8858b1"
      },
      "source": [
        "<div align=\"center\">\n",
        "\n",
        "![ChromDB](https://user-images.githubusercontent.com/891664/227103090-6624bf7d-9524-4e05-9d2c-c28d5d451481.png)\n",
        "</div>\n",
        "\n",
        "**[ChromaDB](https://www.trychroma.com/)** similar to Pinecone is designed to handle vector storage and retrieval. It offers a robust set of features that cater to varoius use cases, making it a viable choice for many vector-based applications.\n",
        "\n",
        "</br>\n",
        "\n",
        "| Aspect                 | Pinecone (Managed)                           | Chroma (Open-source)                        |\n",
        "|-------------------------|-----------------------------------------------|---------------------------------------------|\n",
        "| **Speed**              | Fast similarity search in real-time           | Good performance with flexible queries       |\n",
        "| **Scalability**        | Effortless scaling without infrastructure work| Requires manual setup for scaling            |\n",
        "| **Indexing**           | Automatic indexing, minimal dev effort        | Customizable indexing, more control          |\n",
        "| **Ecosystem**          | Easy-to-use Python SDK                       | Open-source, free, and community-driven      |\n",
        "| **Flexibility**        | Limited advanced queries                      | Supports complex queries (vectors + metadata)|\n",
        "| **Cost**               | Paid, can be expensive at scale               | Free, but infra cost and setup complexity    |\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use **ChromaDB** for semantic vector storage and search, we’ll need:\n",
        "\n",
        "* `langchain`: for chaining and embedding integration  \n",
        "* `chromadb`: the official Chroma client  \n",
        "* Either:\n",
        "  * `openai` + `tiktoken`: for **OpenAI embeddings**  \n",
        "  * `google-generativeai`: for **Gemini embeddings**  \n",
        "\n",
        "\n",
        "### Steps\n",
        "\n",
        "1. **Install and Set Up Chroma**  \n",
        "   Run Chroma locally or on your cloud platform. You can use the `chromadb` package to manage collections directly, without needing a separate managed service.  \n",
        "\n",
        "2. **Integrate Chroma Client**  \n",
        "   Use the Chroma client in your application (via Python SDK or REST API) to connect and define collections for storing embeddings.  \n",
        "\n",
        "3. **Generate Embeddings**  \n",
        "   Use an embedding model (from OpenAI or Gemini) to convert text into numerical vector representations.  \n",
        "\n",
        "4. **Index Vectors**  \n",
        "   Insert the generated embeddings into a Chroma collection, along with any metadata (such as original text, tags, or attributes).  \n",
        "\n",
        "5. **Query Vectors**  \n",
        "   Convert a new query into an embedding and use Chroma’s query functions to retrieve the most similar vectors, filtered or combined with metadata as needed.  \n"
      ],
      "metadata": {
        "id": "LFimiLPJOZKk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nn3H5_ejUhPr"
      },
      "outputs": [],
      "source": [
        "# Install necessary libraries\n",
        "!pip install langchain langchain-community chromadb langchain-chroma -q\n",
        "!pip install google-ai-generativelanguage langchain-google-genai -q"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s download some news articles from [Dropbox]( https://www.dropbox.com/s/vs6ocyvpzzncvwh/new_articles.zip) and use them as our dataset for vector database search and rerieval."
      ],
      "metadata": {
        "id": "qeH8sVXSxb3S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://www.dropbox.com/s/vs6ocyvpzzncvwh/new_articles.zip\n",
        "!unzip -q new_articles.zip -d new_articles"
      ],
      "metadata": {
        "id": "AMNyRKxjOzU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")"
      ],
      "metadata": {
        "id": "UFi1xi3bwNZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
        "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
        "\n",
        "# Load Embeddings and LLM Models\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"text-embedding-004\")\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")"
      ],
      "metadata": {
        "id": "lkg25JZhynGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load all the *.txt files at once using DirectoryLoader\n",
        "loader = DirectoryLoader(\"new_articles\", glob=\"./*.txt\", loader_cls=TextLoader)\n",
        "documents = loader.load()"
      ],
      "metadata": {
        "id": "9cOG_JlCzv05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(documents[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLrSKzpC0GJJ",
        "outputId": "22569515-044c-460c-ff35-9213aa3c0cd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "As brands incorporate generative AI into their creative workflows to generate new content associated with the company, they need to tread carefully to be sure that the new material adheres to the company’s style and brand guidelines.\n",
            "\n",
            "Nova is an early-stage startup building a suite of generative AI tools designed to protect brand integrity, and today, the company is announcing two new products to help brands police AI-generated content: BrandGuard and BrandGPT.\n",
            "\n",
            "With BrandGuard, you ingest your company’s brand guidelines and style guide, and with a series of models Nova has created, it can check the content against those rules to make sure it’s in compliance, while BrandGPT lets you ask questions about the brand’s content rules in ChatGPT style.\n",
            "\n",
            "Rob May, founder and CEO at the company, who previously founded Backupify, a cloud backup startup that was acquired by Datto back in 2014, recognized that companies wanted to start taking advantage of generative AI technology to create content faster, but they still worried about maintaining brand integrity, so he came up with the idea of building a guard rail system to protect the brand from generative AI mishaps.\n",
            "\n",
            "“We heard from multiple CMOs who were worried about ‘how do I know this AI-generated content is on brand?’ So we built this architecture that we’re launching called BrandGuard, which is a really interesting series of models, along with BrandGPT, which acts as an interface on top of the models,” May told TechCrunch.\n",
            "\n",
            "BrandGuard is like the back end for this brand protection system. Nova built five models that look for things that might seem out of whack. They run checks for brand safety, quality checking, whether it’s on brand, whether it adheres to style and whether it’s on campaign. Then it assigns each piece with a content score, and each company can decide what the threshold is for calling in a human to check the content before publishing.\n",
            "\n",
            "“When you have generative AI creating stuff, you can now score it on a continuum. And then you can set thresholds, and if something’s below, say 85% on brand, you can have the system flag it so that a human can take a look at it,” he said. Companies can decide whatever threshold they’re comfortable with.\n",
            "\n",
            "BrandGPT is designed for working with third parties like an agency or a contractor, who can ask questions about the company’s brand guidelines to make sure they are complying with them, May said. “We’re launching BrandGPT, which is meant to be the interface to all this brand-related security stuff that we’re doing, and as people interact with brands, they can access the style guides and better understand the brand, whether they’re a part of the company or not.\n",
            "\n",
            "These two products are available in public beta starting today. The company launched last year and has raised $2.4 million from Bee Partners, Fyrfly Ventures and Argon Ventures.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s move on to **splitting the texts we loaded**. This is useful because we **don’t need to send the entire long text to the API**, which:\n",
        "\n",
        "* **Saves tokens**: reduces costs when using embedding or LLM models.\n",
        "* **Improves relevance**: smaller chunks make semantic search and retrieval more accurate.\n",
        "* **Speeds up processing**: shorter texts are faster to embed and query.\n",
        "\n",
        "By splitting our documents into manageable chunks, we ensure that **each piece of text retains enough context** for meaningful embeddings without exceeding model limits.\n"
      ],
      "metadata": {
        "id": "Tmnapo_i31If"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Feed textual data from documents to text-splitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1024,\n",
        "    chunk_overlap=128,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
        ")\n",
        "\n",
        "texts = text_splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "P3XzZnRR0G1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts[0].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        },
        "id": "ohO-1BwL5PDn",
        "outputId": "e4745938-46c4-4c15-d686-f0dc1290eb02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'As brands incorporate generative AI into their creative workflows to generate new content associated with the company, they need to tread carefully to be sure that the new material adheres to the company’s style and brand guidelines.\\n\\nNova is an early-stage startup building a suite of generative AI tools designed to protect brand integrity, and today, the company is announcing two new products to help brands police AI-generated content: BrandGuard and BrandGPT.\\n\\nWith BrandGuard, you ingest your company’s brand guidelines and style guide, and with a series of models Nova has created, it can check the content against those rules to make sure it’s in compliance, while BrandGPT lets you ask questions about the brand’s content rules in ChatGPT style.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts[1].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        },
        "id": "9mqcJWZE5XZl",
        "outputId": "056036e3-8b28-49d5-a2d4-3ac5629508b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Rob May, founder and CEO at the company, who previously founded Backupify, a cloud backup startup that was acquired by Datto back in 2014, recognized that companies wanted to start taking advantage of generative AI technology to create content faster, but they still worried about maintaining brand integrity, so he came up with the idea of building a guard rail system to protect the brand from generative AI mishaps.\\n\\n“We heard from multiple CMOs who were worried about ‘how do I know this AI-generated content is on brand?’ So we built this architecture that we’re launching called BrandGuard, which is a really interesting series of models, along with BrandGPT, which acts as an interface on top of the models,” May told TechCrunch.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(texts))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCRjabIO6UZl",
        "outputId": "cc1498e6-afc8-4907-9584-92c0db882b32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a Chroma Vector Database\n",
        "\n",
        "Unlike Pinecone that runs through cloud servers, **Chroma** uses **local storage**, which means all your vectors and metadata are stored directly on your machine or chosen infrastructure.\n",
        "\n",
        "This provides full control over data, flexibility, and cost savings, but requires you to manage the environment yourself.\n",
        "\n",
        "> ChromaDB needs a `persistent_directory` to save indices and vectors for **long-term storage**, so that your embeddings, metadata, and collection state are retained across sessions and can be reloaded later without rebuilding the database from scratch."
      ],
      "metadata": {
        "id": "_eRRI3dF6qxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vector_db = Chroma.from_documents(\n",
        "    documents=texts,\n",
        "    embedding=embeddings,         # Gemini -> text-embedding-004\n",
        "    persist_directory=\"chromadb\"\n",
        ")"
      ],
      "metadata": {
        "id": "a84flToO6lvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory File structure\n",
        "# !sudo apt install tree -q\n",
        "!tree chromadb/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wunKHmjN7aXm",
        "outputId": "0eba3afd-7326-494a-9d2b-73c7b763fe26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01;34mchromadb/\u001b[0m\n",
            "├── \u001b[01;34m555d182e-b0f7-457d-acd8-841a6b3b2e47\u001b[0m\n",
            "│   ├── \u001b[00mdata_level0.bin\u001b[0m\n",
            "│   ├── \u001b[00mheader.bin\u001b[0m\n",
            "│   ├── \u001b[00mlength.bin\u001b[0m\n",
            "│   └── \u001b[00mlink_lists.bin\u001b[0m\n",
            "└── \u001b[00mchroma.sqlite3\u001b[0m\n",
            "\n",
            "1 directory, 5 files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| File                     | Description                                                                 |\n",
        "|--------------------------------------|-----------------------------------------------------------------------------|\n",
        "| `data_level0.bin`                     | Stores the **vector embeddings** in binary format (float32 arrays)         |\n",
        "| `header.bin`                          | Contains **metadata about vector blocks**, number of vectors, dimensions   |\n",
        "| `length.bin`                          | Keeps **length information** of vectors or chunks for reconstruction       |\n",
        "| `link_lists.bin`                      | Stores **graph connectivity / ANN links** for fast similarity search       |\n",
        "| `chroma.sqlite3`                      | SQLite DB storing **collection metadata, vector IDs, document metadata**   |\n",
        "\n",
        "* **Binary files (`.bin`)**: heavy numeric/vector data + indexing for fast retrieval\n",
        "* **SQLite file (`.sqlite3`)**: lightweight metadata and collection management\n"
      ],
      "metadata": {
        "id": "mfs-LL8A8GMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vector_db"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AjNYLIB7rZ-",
        "outputId": "154eccb7-5139-4565-e069-16f9451e5807"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain_community.vectorstores.chroma.Chroma at 0x7b9f3e3cb440>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Now lets set `vector_db` to None and Reload the `vector_db` from persisted directory again."
      ],
      "metadata": {
        "id": "5rgmuzXP-nef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vector_db = None\n",
        "vector_db"
      ],
      "metadata": {
        "id": "OOJvVIpU9mlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_chroma import Chroma\n",
        "\n",
        "vector_db = Chroma(\n",
        "    persist_directory=\"chromadb\",\n",
        "    embedding_function=embeddings\n",
        ")\n",
        "\n",
        "vector_db"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WrlQHxx934k",
        "outputId": "f210c1d6-ba42-48d8-a20b-ec2cb6c416e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain_chroma.vectorstores.Chroma at 0x7b9f3cf342c0>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating Retriever"
      ],
      "metadata": {
        "id": "2XQCZg4k-xxE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "| Aspect               | Similarity Search                                                                                                                                   | Maximum Marginal Relevance (MMR) Retrieval                                                                         |\n",
        "| -------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------ |\n",
        "| **Goal**             | Retrieve vectors that are **most similar** to the query                                                                                             | Retrieve vectors that are **both relevant and diverse**                                                            |\n",
        "| **How it works**     | Computes **cosine similarity (or other distance metric)** between the query embedding and all stored embeddings, then returns top-k closest matches | Balances **relevance** (similarity to query) and **novelty** (dissimilarity to already selected items) iteratively |\n",
        "| **Output**           | Top-k results that are closest in embedding space                                                                                                   | Top-k results that cover multiple aspects or subtopics, avoiding redundancy                                        |\n",
        "| **Best for**         | Simple retrieval tasks, FAQs, or single-topic queries                                                                                               | Summarization, RAG pipelines, or multi-aspect query results where diversity matters                                |\n",
        "| **Complexity**       | Low — just compute similarities and sort                                                                                                            | Higher — iterative selection with relevance-diversity trade-off                                                    |\n",
        "| **Example use case** | Searching for similar news articles based on content                                                                                                | Selecting a diverse set of news articles covering different subtopics for a query                                  |\n",
        "\n",
        "\n",
        "#### Key Intuition\n",
        "\n",
        "* **Similarity search** = “Which items are most like my query?”\n",
        "* **MMR retrieval** = “Which items are most like my query **without repeating the same information**?”\n"
      ],
      "metadata": {
        "id": "r0YymYrXAmgA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vector_db.as_retriever(\n",
        "    search_type=\"similarity\", # Default\n",
        "    search_kwargs={\"k\": 3}    # Default: 4\n",
        ")\n",
        "\n",
        "relevant_docs = retriever.invoke(input=\"How much money did Microsft raise?\")\n",
        "relevant_docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLg4kvM2-G4R",
        "outputId": "5de62f9c-6839-4d1e-d834-911b30762bd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='f3381b10-b121-4b58-af66-25df78451ac3', metadata={'source': 'new_articles/05-03-chatgpt-everything-you-need-to-know-about-the-ai-powered-chatbot.txt'}, page_content='April 28, 2023\\n\\nVC firms including Sequoia Capital, Andreessen Horowitz, Thrive and K2 Global are picking up new shares, according to documents seen by TechCrunch. A source tells us Founders Fund is also investing. Altogether the VCs have put in just over $300 million at a valuation of $27 billion to $29 billion. This is separate to a big investment from Microsoft announced earlier this year, a person familiar with the development told TechCrunch, which closed in January. The size of Microsoft’s investment is believed to be around $10 billion, a figure we confirmed with our source.\\n\\nApril 25, 2023\\n\\nCalled ChatGPT Business, OpenAI describes the forthcoming offering as “for professionals who need more control over their data as well as enterprises seeking to manage their end users.”'),\n",
              " Document(id='81aba30f-1da4-4fb3-97aa-761394e015b1', metadata={'source': 'new_articles/05-03-checks-the-ai-powered-data-protection-project-incubated-in-area-120-officially-exits-to-google.txt'}, page_content='Updated with more information about Checks’ valuation and quote from Google.'),\n",
              " Document(id='ac6ea69d-a7bb-4ac8-9ee1-ccfd4e3ee2ed', metadata={'source': 'new_articles/05-06-amazon-launches-free-channels-check-marks-come-to-gmail-and-openai-raises-more-moolah.txt'}, page_content='Get your TechCrunch fix IRL. Join us at Disrupt 2023 in San Francisco this September to immerse yourself in all things startup. From headline interviews to intimate roundtables to a jam-packed startup expo floor, there’s something for everyone at Disrupt. Save up to $800 when you buy your pass now through May 15, and save 15% on top of that with promo code WIR. Learn more.')]"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "relevant_docs[0].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        },
        "id": "jn33ZU03_Yr4",
        "outputId": "ad506cf8-4efb-4b8b-d4d7-b096e23d5a39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'April 28, 2023\\n\\nVC firms including Sequoia Capital, Andreessen Horowitz, Thrive and K2 Global are picking up new shares, according to documents seen by TechCrunch. A source tells us Founders Fund is also investing. Altogether the VCs have put in just over $300 million at a valuation of $27 billion to $29 billion. This is separate to a big investment from Microsoft announced earlier this year, a person familiar with the development told TechCrunch, which closed in January. The size of Microsoft’s investment is believed to be around $10 billion, a figure we confirmed with our source.\\n\\nApril 25, 2023\\n\\nCalled ChatGPT Business, OpenAI describes the forthcoming offering as “for professionals who need more control over their data as well as enterprises seeking to manage their end users.”'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mmr_retriever = vector_db.as_retriever(\n",
        "    search_type=\"mmr\",\n",
        "    search_kwargs={\"k\": 3}    # Default: 4\n",
        ")\n",
        "\n",
        "mmr_relevant_docs = mmr_retriever.invoke(input=\"How much money did Microsft raise?\")\n",
        "mmr_relevant_docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJHlsFdu_1FP",
        "outputId": "4b70eec0-503a-48f4-8430-e843e47f0f95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='f3381b10-b121-4b58-af66-25df78451ac3', metadata={'source': 'new_articles/05-03-chatgpt-everything-you-need-to-know-about-the-ai-powered-chatbot.txt'}, page_content='April 28, 2023\\n\\nVC firms including Sequoia Capital, Andreessen Horowitz, Thrive and K2 Global are picking up new shares, according to documents seen by TechCrunch. A source tells us Founders Fund is also investing. Altogether the VCs have put in just over $300 million at a valuation of $27 billion to $29 billion. This is separate to a big investment from Microsoft announced earlier this year, a person familiar with the development told TechCrunch, which closed in January. The size of Microsoft’s investment is believed to be around $10 billion, a figure we confirmed with our source.\\n\\nApril 25, 2023\\n\\nCalled ChatGPT Business, OpenAI describes the forthcoming offering as “for professionals who need more control over their data as well as enterprises seeking to manage their end users.”'),\n",
              " Document(id='81aba30f-1da4-4fb3-97aa-761394e015b1', metadata={'source': 'new_articles/05-03-checks-the-ai-powered-data-protection-project-incubated-in-area-120-officially-exits-to-google.txt'}, page_content='Updated with more information about Checks’ valuation and quote from Google.'),\n",
              " Document(id='c0a63ef2-70fa-4d4a-b7d2-2d28c7d0be5d', metadata={'source': 'new_articles/05-05-vint-cerf-on-the-exhilarating-mix-of-thrill-and-hazard-at-the-frontiers-of-tech.txt'}, page_content='Even simple systems have the ability to surprise you. Especially when you have simple systems when a large number of them are interacting with each other. I’ve found myself not necessarily recognizing when these emergent properties will come, but I will say that whenever something gets monetized, you should anticipate there will be emergent properties and possibly unexpected behavior, all driven by greed.\\n\\nLet me ask you about some some other stuff you’re working on. I’m always happy when I see cutting-edge tech being applied to people who need it, people with disabilities, people who like just have not been addressed by the current use cases of tech. Are you still working in the accessibility community?')]"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Let's check last index results and compare the results of two different search retriever."
      ],
      "metadata": {
        "id": "aMvwfY1nBJLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "relevant_docs[-1].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "id": "qLL98L3SAJQP",
        "outputId": "6e4036ba-c47c-46fe-8661-12b6cf2c9f22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Get your TechCrunch fix IRL. Join us at Disrupt 2023 in San Francisco this September to immerse yourself in all things startup. From headline interviews to intimate roundtables to a jam-packed startup expo floor, there’s something for everyone at Disrupt. Save up to $800 when you buy your pass now through May 15, and save 15% on top of that with promo code WIR. Learn more.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mmr_relevant_docs[-1].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "J9H7jO82A-s3",
        "outputId": "1189471d-036f-46c1-ae75-bc62e442d382"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Even simple systems have the ability to surprise you. Especially when you have simple systems when a large number of them are interacting with each other. I’ve found myself not necessarily recognizing when these emergent properties will come, but I will say that whenever something gets monetized, you should anticipate there will be emergent properties and possibly unexpected behavior, all driven by greed.\\n\\nLet me ask you about some some other stuff you’re working on. I’m always happy when I see cutting-edge tech being applied to people who need it, people with disabilities, people who like just have not been addressed by the current use cases of tech. Are you still working in the accessibility community?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Refine the response using LLM"
      ],
      "metadata": {
        "id": "491MGAlI-4C4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# Setting up a system prompt\n",
        "system_prompt = (\n",
        "    \"You are Luma, a friendly and knowledgeable AI assistant. \"\n",
        "    \"Answer questions using only the provided context. \"\n",
        "    \"If the answer is not in the context, respond with 'I don’t know.' \"\n",
        "    \"Keep answers concise, clear, and easy to understand. \"\n",
        "    \"Context: {context}\"\n",
        ")\n",
        "\n",
        "# Chat Prompt Template\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_prompt),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "retriever = vector_db.as_retriever(\n",
        "    search_type=\"similarity_score_threshold\",\n",
        "    search_kwargs={\"k\": 2, \"score_threshold\": 0.5}\n",
        ")\n",
        "\n",
        "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
        "chain = create_retrieval_chain(retriever, question_answer_chain)"
      ],
      "metadata": {
        "id": "9r_9ZG6uBWIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chain.invoke({\"input\": \"Can you give summary of new Hugging Face Code completion Model?\"})\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRVUQZiICxZg",
        "outputId": "59415e7e-6369-4e2e-9150-798d233c0f1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input': 'Can you give summary of new Hugging Face Code completion Model?', 'context': [Document(id='7c51b641-bee9-4dd4-a664-08ef897be7c5', metadata={'source': 'new_articles/05-04-hugging-face-and-servicenow-release-a-free-code-generating-model.txt'}, page_content='“One thing we learned from releases such as Stable Diffusion last year is the creativity and capability of the open-source community,” von Werra told TechCrunch in an email interview. “Within weeks of the release the community had built dozens of variants of the model as well as custom applications. Releasing a powerful code generation model allows anybody to fine-tune and adapt it to their own use-cases and will enable countless downstream applications.”\\n\\nBuilding a model\\n\\nStarCoder is a part of Hugging Face’s and ServiceNow’s over-600-person BigCode project, launched late last year, which aims to develop “state-of-the-art” AI systems for code in an “open and responsible” way. Hugging Face supplied an in-house compute cluster of 512 Nvidia V100 GPUs to train the StarCoder model.'), Document(id='483bc260-ccb3-4384-af6d-750b7b3c1a4c', metadata={'source': 'new_articles/05-04-hugging-face-and-servicenow-release-a-free-code-generating-model.txt'}, page_content='“At launch, StarCoder will not ship as many features as GitHub Copilot, but with its open-source nature, the community can help improve it along the way as well as integrate custom models,” he said.\\n\\nThe StarCoder code repositories, model training framework, dataset-filtering methods, code evaluation suite and research analysis notebooks are available on GitHub as of this week. The BigCode project will maintain them going forward as the groups look to develop more capable code-generating models, fueled by input from the community.\\n\\nThere’s certainly work to be done. In the technical paper accompanying StarCoder’s release, Hugging Face and ServiceNow say that the model may produce inaccurate, offensive, and misleading content as well as PII and malicious code that managed to make it past the dataset filtering stage.')], 'answer': \"Hugging Face, as part of the BigCode project with ServiceNow, has released StarCoder, a powerful open-source code generation model. It was trained using 512 Nvidia V100 GPUs. StarCoder's code repositories, training framework, dataset-filtering methods, code evaluation suite, and research analysis notebooks are available on GitHub. While it may not have as many features as GitHub Copilot at launch, its open-source nature allows the community to fine-tune, adapt, and improve it. However, the model may produce inaccurate, offensive, misleading content, PII, and malicious code.\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response[\"context\"][0].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        },
        "id": "FpXK7VVmEZE7",
        "outputId": "4aaac590-d474-4598-987f-4d144d1de287"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'“One thing we learned from releases such as Stable Diffusion last year is the creativity and capability of the open-source community,” von Werra told TechCrunch in an email interview. “Within weeks of the release the community had built dozens of variants of the model as well as custom applications. Releasing a powerful code generation model allows anybody to fine-tune and adapt it to their own use-cases and will enable countless downstream applications.”\\n\\nBuilding a model\\n\\nStarCoder is a part of Hugging Face’s and ServiceNow’s over-600-person BigCode project, launched late last year, which aims to develop “state-of-the-art” AI systems for code in an “open and responsible” way. Hugging Face supplied an in-house compute cluster of 512 Nvidia V100 GPUs to train the StarCoder model.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response[\"answer\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "ap5CSqhwEDgp",
        "outputId": "57086b02-0e4c-4fb1-c3d5-b2715210cb38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Hugging Face, as part of the BigCode project with ServiceNow, has released StarCoder, a powerful open-source code generation model. It was trained using 512 Nvidia V100 GPUs. StarCoder's code repositories, training framework, dataset-filtering methods, code evaluation suite, and research analysis notebooks are available on GitHub. While it may not have as many features as GitHub Copilot at launch, its open-source nature allows the community to fine-tune, adapt, and improve it. However, the model may produce inaccurate, offensive, misleading content, PII, and malicious code.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = chain.invoke({\"input\": \"How much money did OpenAI raise?\"})\n",
        "response[\"answer\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "XxmNSAjRDB33",
        "outputId": "4c9cc28f-c90d-40ce-ab33-3aaaaa15ae55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'OpenAI raised just over $300 million from VC firms including Sequoia Capital, Andreessen Horowitz, Thrive, K2 Global, and Founders Fund. This is separate from a Microsoft investment of around $10 billion.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> You can also save the ChromaDB contents in zip file and then re-use by reloading later."
      ],
      "metadata": {
        "id": "gNLuzkqm_F64"
      }
    }
  ]
}